{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Can I can use GPU now? -- True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdb\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import ipdb\n",
    "\n",
    "# Pipelines (a.k.a parts of the Neural Network)\n",
    "from Pipelines.kitti_loader import KITTIDataset\n",
    "from Pipelines.pillarizer import PillarFeatureNet, Pillarization, PseudoImageDataset\n",
    "from Pipelines.backbone import BackBone\n",
    "from Pipelines.detection_head import DetectionHead\n",
    "from Pipelines.anchors import Box2D, Anchor\n",
    "#from Pipelines.loss import PointPillarLoss\n",
    "\n",
    "from Utils.transformations import transform_to_canvas, transform_to_grid, map_to_img\n",
    "from Utils.iou import calculate_iou\n",
    "from Utils.collate import normalize_annotations\n",
    "from Utils.boxes import create_boxes_tensor # FIXME: Should be in visualization instead\n",
    "\n",
    "# Visualization tools:\n",
    "from Visualization.visz_pointcloud_w_label import plot_point_cloud_with_bboxes_o3d\n",
    "from Visualization.visz_bboxes import visualize_batch_bounding_boxes\n",
    "\n",
    "\n",
    "# Some Neural Network Parameters:\n",
    "AUG_DIM = 9\n",
    "MAX_POINTS_PER_PILLAR = 100\n",
    "MAX_FILLED_PILLARS = 12000\n",
    "X_MIN = 0.0\n",
    "X_MAX = 70.4\n",
    "Y_MIN = -40.0\n",
    "Y_MAX = 40.0\n",
    "Z_MIN = -3.0\n",
    "Z_MAX = 1.0\n",
    "PILLAR_SIZE = (0.16, 0.16)\n",
    "DESIRED_CLASSES = ['Car'] # More classes can be added here\n",
    "SCALE_FACTOR = 1.5\n",
    "H = 500\n",
    "W = 440\n",
    "\n",
    "\n",
    "ANCHORS = torch.tensor([[3.9, 1.6, 1.56, -1, 0], # Anchors as tensor: (height, width, height, z_center, orientation)\n",
    "                       [1.6, 3.9, 1.56, -1, 1.5708],\n",
    "                       [0.8, 0.6, 1.73, -0.6, 0],\n",
    "                       [0.6, 0.8, 1.73, -0.6, 1.5708]]\n",
    "                       )\n",
    "\n",
    "mapped_anchors = ANCHORS.detach().clone()\n",
    "mapped_anchors[:,0:2] /= PILLAR_SIZE[0]\n",
    "\n",
    "\n",
    "# Define a dictionary to map attributes to their indices\n",
    "attributes_idx = {\n",
    "    'norm_x': 7,\n",
    "    'norm_y': 8,\n",
    "    'norm_z': 9,\n",
    "    'norm_h': 10,\n",
    "    'norm_w': 11,\n",
    "    'norm_l': 12,\n",
    "}\n",
    "\n",
    "for anchor_tensor in mapped_anchors: # NOTE: This is regardless of the batch, it is for all the training and testing\n",
    "    anchor = Anchor(width=anchor_tensor[1], height=anchor_tensor[0])\n",
    "    anchor.create_anchor_grid(H,W) # Creates grid\n",
    "    anchor.create_anchors()\n",
    "    break # FIXME: Get rid of this\n",
    "    #anchors_list.append(anchor)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Can I can use GPU now? -- {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create data loaders'''\n",
    "\n",
    "train_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/velodyne_reduced'\n",
    "train_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/label_2'\n",
    "\n",
    "small_train_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne'\n",
    "small_train_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_labels_velodyne'\n",
    "\n",
    "mini_train_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_train_velodyne'\n",
    "mini_train_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_label_velodyne'\n",
    "\n",
    "\n",
    "test_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/testing/velodyne_reduced'\n",
    "\n",
    "\n",
    "# IMPORTANT: Set to CPU for pillarization otherwise, expect GPU memory to overflow\n",
    "device =  torch.device('cpu')\n",
    "\n",
    "\n",
    "# Create a collate function to handle variable-sized labels:\n",
    "def collate_batch(batch):\n",
    "    point_clouds, annotations = zip(*batch)\n",
    "    point_clouds = torch.stack(point_clouds, dim=0)\n",
    "    normalized_annotations = normalize_annotations(annotations, pillar_size=PILLAR_SIZE,\n",
    "        x_lims=(X_MIN, X_MAX), y_lims=(Y_MIN, Y_MAX))\n",
    "    \n",
    "    return point_clouds, normalized_annotations\n",
    "\n",
    "\n",
    "train_set = KITTIDataset(pointcloud_dir=small_train_pointclouds_dir, labels_dir=small_train_labels_dir)\n",
    "        \n",
    "# Create the dataset and DataLoader\n",
    "dataset = PseudoImageDataset(pointcloud_dir=small_train_pointclouds_dir, device=device, kitti_dataset=train_set, aug_dim=AUG_DIM, max_points_in_pillar=MAX_POINTS_PER_PILLAR,\n",
    "                             max_pillars=MAX_FILLED_PILLARS, x_min=X_MIN, y_min=Y_MIN, z_min=Z_MIN, x_max = X_MAX, y_max=Y_MAX,\n",
    "                             z_max = Z_MAX, pillar_size=PILLAR_SIZE)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=False, collate_fn=collate_batch) # FIXME: Set batch to 4 again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000506.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/Pipelines/kitti_loader.py:50: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.from_numpy(point_cloud)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading point cloud number 665\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000040.bin\n",
      "Loading point cloud number 574\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000248.bin\n",
      "Loading point cloud number 610\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000770.bin\n",
      "Loading point cloud number 421\n",
      "Loss: 18.80075454711914\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000356.bin\n",
      "Loading point cloud number 500\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000396.bin\n",
      "Loading point cloud number 431\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000276.bin\n",
      "Loading point cloud number 613\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000260.bin\n",
      "Loading point cloud number 783\n",
      "Loss: 27.337766647338867\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000106.bin\n",
      "Loading point cloud number 3\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000904.bin\n",
      "Loading point cloud number 285\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000085.bin\n",
      "Loading point cloud number 651\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000222.bin\n",
      "Loading point cloud number 414\n",
      "Loss: 25.872995376586914\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000845.bin\n",
      "Loading point cloud number 606\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000375.bin\n",
      "Loading point cloud number 32\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000816.bin\n",
      "Loading point cloud number 846\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000521.bin\n",
      "Loading point cloud number 109\n",
      "Loss: 15.994684219360352\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000125.bin\n",
      "Loading point cloud number 253\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000055.bin\n",
      "Loading point cloud number 692\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000373.bin\n",
      "Loading point cloud number 257\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000240.bin\n",
      "Loading point cloud number 974\n",
      "Loss: 28.742347717285156\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000046.bin\n",
      "Loading point cloud number 349\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000549.bin\n",
      "Loading point cloud number 371\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000783.bin\n",
      "Loading point cloud number 467\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000210.bin\n",
      "Loading point cloud number 127\n",
      "Loss: 28.54205894470215\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000947.bin\n",
      "Loading point cloud number 764\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000776.bin\n",
      "Loading point cloud number 922\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000777.bin\n",
      "Loading point cloud number 994\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000104.bin\n",
      "Loading point cloud number 14\n",
      "Loss: 18.32715606689453\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000628.bin\n",
      "Loading point cloud number 200\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000246.bin\n",
      "Loading point cloud number 463\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000909.bin\n",
      "Loading point cloud number 691\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000184.bin\n",
      "Loading point cloud number 369\n",
      "Loss: 18.18211555480957\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000045.bin\n",
      "Loading point cloud number 929\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000542.bin\n",
      "Loading point cloud number 328\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000708.bin\n",
      "Loading point cloud number 491\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000189.bin\n",
      "Loading point cloud number 104\n",
      "Loss: 19.283971786499023\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000482.bin\n",
      "Loading point cloud number 423\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000146.bin\n",
      "Loading point cloud number 455\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000704.bin\n",
      "Loading point cloud number 588\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000071.bin\n",
      "Loading point cloud number 879\n",
      "Loss: 11.261720657348633\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000789.bin\n",
      "Loading point cloud number 315\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000649.bin\n",
      "Loading point cloud number 147\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000855.bin\n",
      "Loading point cloud number 698\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000965.bin\n",
      "Loading point cloud number 230\n",
      "Loss: 18.139923095703125\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000203.bin\n",
      "Loading point cloud number 899\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000019.bin\n",
      "Loading point cloud number 198\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000663.bin\n",
      "Loading point cloud number 331\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000116.bin\n",
      "Loading point cloud number 736\n",
      "Loss: 16.82016372680664\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000300.bin\n",
      "Loading point cloud number 341\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000626.bin\n",
      "Loading point cloud number 839\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000217.bin\n",
      "Loading point cloud number 55\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000907.bin\n",
      "Loading point cloud number 106\n",
      "Loss: 22.10468864440918\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000669.bin\n",
      "Loading point cloud number 676\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000726.bin\n",
      "Loading point cloud number 419\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000769.bin\n",
      "Loading point cloud number 920\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000160.bin\n",
      "Loading point cloud number 66\n",
      "Loss: 13.572968482971191\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000716.bin\n",
      "Loading point cloud number 122\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000471.bin\n",
      "Loading point cloud number 921\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000287.bin\n",
      "Loading point cloud number 204\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000874.bin\n",
      "Loading point cloud number 721\n",
      "Loss: 13.562979698181152\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000761.bin\n",
      "Loading point cloud number 107\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000595.bin\n",
      "Loading point cloud number 441\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000545.bin\n",
      "Loading point cloud number 590\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000994.bin\n",
      "Loading point cloud number 476\n",
      "Loss: 17.52689552307129\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000944.bin\n",
      "Loading point cloud number 132\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000863.bin\n",
      "Loading point cloud number 943\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000696.bin\n",
      "Loading point cloud number 720\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000350.bin\n",
      "Loading point cloud number 310\n",
      "Loss: 24.644290924072266\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000291.bin\n",
      "Loading point cloud number 769\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000784.bin\n",
      "Loading point cloud number 582\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000245.bin\n",
      "Loading point cloud number 68\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000918.bin\n",
      "Loading point cloud number 23\n",
      "Loss: 18.45384979248047\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000811.bin\n",
      "Loading point cloud number 704\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000519.bin\n",
      "Loading point cloud number 241\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000086.bin\n",
      "Loading point cloud number 376\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000523.bin\n",
      "Loading point cloud number 354\n",
      "Loss: 15.24703598022461\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000006.bin\n",
      "Loading point cloud number 73\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000751.bin\n",
      "Loading point cloud number 149\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000744.bin\n",
      "Loading point cloud number 240\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000996.bin\n",
      "Loading point cloud number 317\n",
      "Loss: 16.873558044433594\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000319.bin\n",
      "Loading point cloud number 799\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000600.bin\n",
      "Loading point cloud number 605\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000257.bin\n",
      "Loading point cloud number 302\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000451.bin\n",
      "Loading point cloud number 886\n",
      "Loss: 18.588150024414062\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000941.bin\n",
      "Loading point cloud number 869\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000409.bin\n",
      "Loading point cloud number 686\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000013.bin\n",
      "Loading point cloud number 439\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000479.bin\n",
      "Loading point cloud number 524\n",
      "Loss: 28.846263885498047\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000157.bin\n",
      "Loading point cloud number 494\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000534.bin\n",
      "Loading point cloud number 135\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000808.bin\n",
      "Loading point cloud number 780\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000995.bin\n",
      "Loading point cloud number 92\n",
      "Loss: 21.68345832824707\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000957.bin\n",
      "Loading point cloud number 290\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000345.bin\n",
      "Loading point cloud number 987\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000294.bin\n",
      "Loading point cloud number 988\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000734.bin\n",
      "Loading point cloud number 564\n",
      "Loss: 15.167551040649414\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000024.bin\n",
      "Loading point cloud number 182\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000322.bin\n",
      "Loading point cloud number 110\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne/000622.bin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class PointPillarLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, beta_loc = 2.0, beta_cls = 1.0):\n",
    "        super(PointPillarLoss, self).__init__()\n",
    "        self.smooth_l1_loss = nn.SmoothL1Loss()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.beta_cls = beta_cls\n",
    "        self.beta_loc = beta_loc\n",
    "\n",
    "\n",
    "    def forward(self, regression_targets, classification_targets_dict, \n",
    "                gt_boxes_tensor, loc, size, clf, occupancy, angle, heading, anchor):\n",
    "        \n",
    "        '''\n",
    "        Inputs: \n",
    "        loc -- size (batch_size, n_anchors, 3, H, W)\n",
    "        size -- size (batch_size, n_anchors, 3, H, W) \n",
    "        clf -- size (batch_size, n_anchors, 3, H, W)\n",
    "        regression_targets -- tensor of size (batch_size, n_boxes, 2) with the indices of the best matching anchors\n",
    "        gt_boxes_tensor -- size (bs, n_boxes, 4)\n",
    "        '''\n",
    "\n",
    "        da = torch.sqrt(anchor.width**2 + anchor.height**2)\n",
    "\n",
    "        # Initialize the predictions\n",
    "        batch_size, n_boxes = regression_targets.shape[:2]\n",
    "        x_pred = torch.zeros(batch_size, n_boxes, dtype=loc.dtype)\n",
    "        y_pred = torch.zeros(batch_size, n_boxes, dtype=loc.dtype)\n",
    "        dx_tensor = torch.zeros(batch_size, n_boxes, dtype=loc.dtype)\n",
    "        dy_tensor = torch.zeros(batch_size, n_boxes, dtype=loc.dtype)\n",
    "        dw_tensor = torch.zeros(batch_size, n_boxes, dtype=loc.dtype)\n",
    "        dl_tensor = torch.zeros(batch_size, n_boxes, dtype=loc.dtype)\n",
    "\n",
    "     \n",
    "        # Classification loss:\n",
    "        '''background probs -- dict{batch: prob_loss}'''\n",
    "        background_focal_loss = 0.0\n",
    "        n_classification_target = 0\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for n_target, cls_target in enumerate(classification_targets_dict[b]):\n",
    "                x_idx = classification_targets_dict[b][n_target][1] #(n_box, x, y)\n",
    "                y_idx = classification_targets_dict[b][n_target][2]\n",
    "                '''clf -- size (batch_size, n_anchors, 3, H, W)'''\n",
    "                clf_val = clf[b][0][0][y_idx][x_idx]\n",
    "                # Apply focal loss\n",
    "                background_focal_loss += -torch.log(clf_val)*self.alpha*(1 - clf_val)**self.gamma\n",
    "                n_classification_target += 1\n",
    "\n",
    "        if batch_size*n_boxes != 0.0:\n",
    "            background_focal_loss /= n_classification_target\n",
    "        else:\n",
    "            background_focal_loss = 0.0\n",
    "            print(f'Division by zero encountered on background!')   \n",
    "\n",
    "\n",
    "        # Regression loss:\n",
    "        car_focal_loss = 0.0\n",
    "        for b in range(batch_size):\n",
    "            for n in range(n_boxes):\n",
    "\n",
    "                x_idx = regression_targets[b, n, 0].long()  # Ensure the indices are long type\n",
    "                y_idx = regression_targets[b, n, 1].long()  # Ensure the indices are long type\n",
    "                x_pred[b, n] = loc[b, 0, 0, y_idx, x_idx]  # Indexing y first as it corresponds to H dimension\n",
    "                y_pred[b, n] = loc[b, 0, 1, y_idx, x_idx]  # Indexing y first as it corresponds to H dimension\n",
    "                w_gt = gt_boxes_tensor[b, n, 3] - gt_boxes_tensor[b, n, 1]\n",
    "                l_gt = gt_boxes_tensor[b, n, 2] - gt_boxes_tensor[b, n, 0]\n",
    "                x_gt = gt_boxes_tensor[b, n, 0] + w_gt/2\n",
    "                y_gt = gt_boxes_tensor[b, n, 1] - l_gt/2\n",
    "                dx_tensor[b, n] = (x_gt - x_pred[b,n]) / da \n",
    "                dy_tensor[b, n] = (y_gt - y_pred[b,n]) / da \n",
    "                # Sizes:\n",
    "                if (w_gt != 0.0):\n",
    "                    dw_tensor[b, n] = torch.log((w_gt / torch.abs(size[b, 0, 0, y_idx, x_idx])))\n",
    "                if (l_gt != 0.0):\n",
    "                    dl_tensor[b, n] = torch.log((l_gt / torch.abs(size[b, 0, 1, y_idx, x_idx])))\n",
    "\n",
    "                #print(f'Added to dw: {dw_tensor[b, n]} its denominator was : {size[b, 0, 0, y_idx, x_idx]}')\n",
    "                #print(f'Added to dl: {dl_tensor[b, n]} its denominator was: {size[b, 0, 1, y_idx, x_idx]}')\n",
    "\n",
    "                # Classification loss for cars:\n",
    "                car_prob = clf[b, 0, 1, y_idx, x_idx]\n",
    "                car_focal_loss += -torch.log(car_prob)*self.alpha*(1 - car_prob)**self.gamma\n",
    "\n",
    "\n",
    "        if batch_size*n_boxes != 0.0:\n",
    "            car_focal_loss /= batch_size*n_boxes\n",
    "        else: \n",
    "            print(f'Division by zero encountered on cars!')\n",
    "            car_focal_loss = 0.0 \n",
    "\n",
    "\n",
    "        # Calculate regression loss:\n",
    "        loc_loss_x = self.smooth_l1_loss(dx_tensor, torch.zeros_like(dx_tensor))\n",
    "        loc_loss_y = self.smooth_l1_loss(dy_tensor, torch.zeros_like(dx_tensor))\n",
    "        width_loss = self.smooth_l1_loss(dw_tensor, torch.zeros_like(dw_tensor))\n",
    "        length_loss = self.smooth_l1_loss(dl_tensor, torch.zeros_like(dl_tensor))\n",
    "\n",
    "        # Calculate classification loss:\n",
    "        total_loc_loss = loc_loss_x + loc_loss_y + width_loss + length_loss\n",
    "\n",
    "        # Calculate regression loss:\n",
    "        total_loss = self.beta_loc*total_loc_loss + self.beta_cls*(background_focal_loss + car_focal_loss)\n",
    "\n",
    "        return total_loss\n",
    "    \n",
    "\n",
    "'''Set up the neural network for training'''\n",
    "\n",
    "class PointPillarsModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointPillarsModel, self).__init__()\n",
    "        self.backbone = BackBone(in_channels=64, out_channels=64, device=torch.device('cuda'))\n",
    "        self.detection_head = DetectionHead(in_channels=384, grid_size_x=500, grid_size_y=440, num_anchors=1, \n",
    "                num_classes=2, device=torch.device('cuda'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through backbone and detection head\n",
    "        features = self.backbone(x)\n",
    "        loc, size, clf, occupancy, angle, heading = self.detection_head(features)\n",
    "        return loc, size, clf, occupancy, angle, heading\n",
    "\n",
    "\n",
    "'''\n",
    "# Declare model:\n",
    "backbone = BackBone(in_channels=64, out_channels=64, device=torch.device('cuda'))\n",
    "\n",
    "detection_head = DetectionHead(device=torch.device('cuda'), in_channels=384, grid_size_x=500, \n",
    "                        grid_size_y=440, num_anchors=1, num_classes=2) \n",
    "\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)'''\n",
    "\n",
    "#def get_classification_targets(self, iou_tensor, feature_map_size, \n",
    "#                               background_lower_threshold=0.05, background_upper_threshold=0.25):\n",
    "\"\"\"\n",
    "Generates classification targets based on IoU thresholds for each anchor.\n",
    "\n",
    "Parameters:\n",
    "iou_tensor -- tensor of IoU values, shape (batch_size, n_boxes, num_anchors_x, num_anchors_y)\n",
    "feature_map_size -- size of the feature map grid (H, W)\n",
    "foreground_threshold -- IoU threshold to consider an anchor as a positive match (foreground)\n",
    "background_lower_threshold -- lower IoU threshold for considering an anchor as a negative match (background)\n",
    "background_upper_threshold -- upper IoU threshold for considering an anchor as a negative match (background)\n",
    "\n",
    "Returns:\n",
    "A dictionary with keys as batch indices and values as lists of (box_index, feature_map_x_index, feature_map_y_index, class_label)\n",
    "\"\"\"\n",
    "\n",
    "n_epochs = 7\n",
    "model = PointPillarsModel()\n",
    "loss_fn = PointPillarLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss = 0.0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    train_set = KITTIDataset(pointcloud_dir=small_train_pointclouds_dir, labels_dir=small_train_labels_dir)\n",
    "        \n",
    "    # Create the dataset and DataLoader\n",
    "\n",
    "    dataset = PseudoImageDataset(pointcloud_dir=small_train_pointclouds_dir, device=device, kitti_dataset=train_set, aug_dim=AUG_DIM, max_points_in_pillar=MAX_POINTS_PER_PILLAR,\n",
    "                             max_pillars=MAX_FILLED_PILLARS, x_min=X_MIN, y_min=Y_MIN, z_min=Z_MIN, x_max = X_MAX, y_max=Y_MAX,\n",
    "                             z_max = Z_MAX, pillar_size=PILLAR_SIZE)\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_batch)\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (pseudo_images, batched_labels) in enumerate(train_loader):\n",
    "\n",
    "        gt_boxes_tensor = create_boxes_tensor(batched_labels, attributes_idx)\n",
    "        \n",
    "        # Check if gt_boxes_tensor is empty for the current batch\n",
    "        if gt_boxes_tensor.nelement() == 0:\n",
    "            print(f'Encountered an empty element on the batch')\n",
    "            continue\n",
    "        \n",
    "        # Get the roi indices:\n",
    "        roi_indices = anchor.get_ROI_indices(gt_boxes_tensor=gt_boxes_tensor, scale_factor=1.5, \n",
    "                    feature_map_size=(H,W))\n",
    "\n",
    "\n",
    "        # Get IoU tensor and regression targets:\n",
    "        iou_tensor = anchor.calculate_batch_iou(gt_boxes_tensor) \n",
    "        '''IoU tensor (batch_size, n_boxes, num_anchors_x, num_anchors_y)'''\n",
    "\n",
    "\n",
    "        regression_targets_tensor = anchor.get_regression_targets_tensor(iou_tensor, (H,W), threshold=0.5)\n",
    "\n",
    "        classification_targets_dict = anchor.get_classification_targets(iou_tensor=iou_tensor, feature_map_size=(H,W),\n",
    "                                    background_lower_threshold=0.05, background_upper_threshold=0.25)\n",
    "        \n",
    "        '''Enable gradients'''\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loc, size, clf, occupancy, angle, heading = model(pseudo_images)\n",
    "\n",
    "        \n",
    "        loss = loss_fn(regression_targets=regression_targets_tensor, classification_targets_dict=classification_targets_dict,\n",
    "        gt_boxes_tensor = gt_boxes_tensor, loc=loc, size=size, clf=clf, occupancy=occupancy, angle=angle, heading=heading,\n",
    "        anchor=anchor)\n",
    "\n",
    "        print(f'Loss: {loss}')\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "model = ...  # Your complete PointPillars model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = PointPillarLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.8)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_data in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform pillarization and forward pass through the model\n",
    "        pillars, coords, ... = pillarize(batch_data)\n",
    "        loc, size, clf, ... = model(pillars, coords)\n",
    "        \n",
    "        # Generate targets using your Anchor class\n",
    "        regression_targets, classification_targets = anchor.generate_targets(batch_data)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(regression_targets, classification_targets, batch_data['gt_boxes'], loc, size, clf, ...)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
