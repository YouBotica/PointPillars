{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Can I can use GPU now? -- True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdb\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import ipdb\n",
    "\n",
    "# Pipelines (a.k.a parts of the Neural Network)\n",
    "from Pipelines.kitti_loader import KITTIDataset\n",
    "from Pipelines.pillarizer import PillarFeatureNet, Pillarization, PseudoImageDataset\n",
    "from Pipelines.backbone import BackBone\n",
    "from Pipelines.detection_head import DetectionHead\n",
    "from Pipelines.anchors import Box2D, Anchor\n",
    "from Pipelines.loss import PointPillarLoss\n",
    "from Pipelines.network import PointPillarsModel\n",
    "\n",
    "from Utils.transformations import transform_to_canvas, transform_to_grid, map_to_img\n",
    "from Utils.iou import calculate_iou\n",
    "from Utils.collate import normalize_annotations\n",
    "from Utils.boxes import create_boxes_tensor # FIXME: Should be in visualization instead\n",
    "\n",
    "# Visualization tools:\n",
    "from Visualization.visz_pointcloud_w_label import plot_point_cloud_with_bboxes_o3d\n",
    "from Visualization.visz_bboxes import visualize_batch_bounding_boxes\n",
    "\n",
    "\n",
    "# Some Neural Network Parameters:\n",
    "AUG_DIM = 9\n",
    "MAX_POINTS_PER_PILLAR = 100\n",
    "MAX_FILLED_PILLARS = 12000\n",
    "X_MIN = 0.0\n",
    "X_MAX = 70.4\n",
    "Y_MIN = -40.0\n",
    "Y_MAX = 40.0\n",
    "Z_MIN = -3.0\n",
    "Z_MAX = 1.0\n",
    "PILLAR_SIZE = (0.16, 0.16)\n",
    "#DESIRED_CLASSES = ['Car'] # More classes can be added here DEPRECATE?\n",
    "SCALE_FACTOR = 1.5\n",
    "H = 500\n",
    "W = 440\n",
    "\n",
    "\n",
    "ANCHORS = torch.tensor([[3.9, 1.6, 1.56, -1, 0], # Anchors as tensor: (height, width, height, z_center, orientation)\n",
    "                       [1.6, 3.9, 1.56, -1, 1.5708],\n",
    "                       [0.8, 0.6, 1.73, -0.6, 0],\n",
    "                       [0.6, 0.8, 1.73, -0.6, 1.5708]]\n",
    "                       )\n",
    "\n",
    "mapped_anchors = ANCHORS.detach().clone()\n",
    "mapped_anchors[:,0:2] /= PILLAR_SIZE[0]\n",
    "\n",
    "\n",
    "# Define a dictionary to map attributes to their indices\n",
    "attributes_idx = {\n",
    "    'norm_x': 7,\n",
    "    'norm_y': 8,\n",
    "    'norm_z': 9,\n",
    "    'norm_h': 10,\n",
    "    'norm_w': 11,\n",
    "    'norm_l': 12,\n",
    "}\n",
    "\n",
    "for anchor_tensor in mapped_anchors: # NOTE: This is regardless of the batch, it is for all the training and testing\n",
    "    anchor = Anchor(width=anchor_tensor[1], height=anchor_tensor[0])\n",
    "    anchor.create_anchor_grid(H,W) # Creates grid\n",
    "    anchor.create_anchors()\n",
    "    break # FIXME: Get rid of this\n",
    "    #anchors_list.append(anchor)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Can I can use GPU now? -- {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create data loaders'''\n",
    "\n",
    "train_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/velodyne_reduced'\n",
    "train_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/label_2'\n",
    "\n",
    "small_train_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne'\n",
    "small_train_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_labels_velodyne'\n",
    "\n",
    "mini_train_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_train_velodyne'\n",
    "mini_train_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_label_velodyne'\n",
    "\n",
    "small_validation_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_validation_velodyne'\n",
    "small_validation_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_validation_small_validation_labels'\n",
    "\n",
    "mini_validation_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_validation_velodyne'\n",
    "mini_validation_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_validation_labels'\n",
    "\n",
    "\n",
    "test_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/testing/velodyne_reduced'\n",
    "\n",
    "\n",
    "# IMPORTANT: Set to CPU for pillarization otherwise, expect GPU memory to overflow\n",
    "device =  torch.device('cpu')\n",
    "\n",
    "\n",
    "# Create a collate function to handle variable-sized labels:\n",
    "def collate_batch(batch):\n",
    "    point_clouds, annotations = zip(*batch)\n",
    "    point_clouds = torch.stack(point_clouds, dim=0)\n",
    "    normalized_annotations = normalize_annotations(annotations, pillar_size=PILLAR_SIZE,\n",
    "        x_lims=(X_MIN, X_MAX), y_lims=(Y_MIN, Y_MAX))\n",
    "    \n",
    "    return point_clouds, normalized_annotations\n",
    "\n",
    "\n",
    "train_set = KITTIDataset(pointcloud_dir=mini_train_pointclouds_dir, labels_dir=mini_train_labels_dir)\n",
    "val_set = KITTIDataset(pointcloud_dir=mini_validation_pointclouds_dir, labels_dir=mini_validation_labels_dir)\n",
    "        \n",
    "# Create the dataset and DataLoader\n",
    "train_dataset = PseudoImageDataset(pointcloud_dir=mini_train_pointclouds_dir, device=device, kitti_dataset=train_set, aug_dim=AUG_DIM, max_points_in_pillar=MAX_POINTS_PER_PILLAR,\n",
    "                             max_pillars=MAX_FILLED_PILLARS, x_min=X_MIN, y_min=Y_MIN, z_min=Z_MIN, x_max = X_MAX, y_max=Y_MAX,\n",
    "                             z_max = Z_MAX, pillar_size=PILLAR_SIZE)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "\n",
    "val_dataset = PseudoImageDataset(pointcloud_dir=mini_validation_pointclouds_dir, device=device, kitti_dataset=train_set, aug_dim=AUG_DIM, max_points_in_pillar=MAX_POINTS_PER_PILLAR,\n",
    "                             max_pillars=MAX_FILLED_PILLARS, x_min=X_MIN, y_min=Y_MIN, z_min=Z_MIN, x_max = X_MAX, y_max=Y_MAX,\n",
    "                             z_max = Z_MAX, pillar_size=PILLAR_SIZE)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 0, batch: 0, loss: 33.940834045410156, elapsed: 7.464103937149048\n",
      "Model saved to /home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/saved_models/model_checkpoint.pth\n",
      "Epoch: 1\n",
      "Epoch: 1, batch: 0, loss: 26.576923370361328, elapsed: 7.4014270305633545\n",
      "Model saved to /home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/saved_models/model_checkpoint.pth\n",
      "Epoch: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/train.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/train.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m'''Enable training mode'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/train.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/train.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (pseudo_images, batched_labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/train.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/train.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# Start timer:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/train.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/train.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     gt_boxes_tensor \u001b[39m=\u001b[39m create_boxes_tensor(batched_labels, attributes_idx)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 7\n",
    "model = PointPillarsModel()\n",
    "loss_fn = PointPillarLoss(feature_map_size=(H, W))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss = 0.0\n",
    "\n",
    "# Define a path to save the model\n",
    "model_save_path = \"/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/saved_models/model_checkpoint.pth\"\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    print(f'Epoch: {epoch}')    \n",
    "    '''Enable training mode'''\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (pseudo_images, batched_labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Start timer:\n",
    "        start_time = time.time()\n",
    "\n",
    "\n",
    "        gt_boxes_tensor = create_boxes_tensor(batched_labels, attributes_idx)\n",
    "        \n",
    "        # Check if gt_boxes_tensor is empty for the current batch\n",
    "        if gt_boxes_tensor.nelement() == 0:\n",
    "            print(f'Encountered an empty element on the batch')\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Get IoU tensor and regression targets:\n",
    "        iou_tensor = anchor.calculate_batch_iou(gt_boxes_tensor) \n",
    "        '''IoU tensor (batch_size, n_boxes, num_anchors_x, num_anchors_y)'''\n",
    "\n",
    "        # Regression targets from ground truth labels\n",
    "        regression_targets_tensor = anchor.get_regression_targets_tensor(iou_tensor, (H,W), threshold=0.5)\n",
    "\n",
    "        # Classification targets:\n",
    "        classification_targets_dict = anchor.get_classification_targets(iou_tensor=iou_tensor, feature_map_size=(H,W),\n",
    "                                    background_lower_threshold=0.05, background_upper_threshold=0.25)\n",
    "        \n",
    "        \n",
    "        '''Refresh gradients for forward pass'''\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loc, size, clf, occupancy, angle, heading = model(pseudo_images)\n",
    "\n",
    "        \n",
    "        loss = loss_fn(regression_targets=regression_targets_tensor, classification_targets_dict=classification_targets_dict,\n",
    "        gt_boxes_tensor = gt_boxes_tensor, loc=loc, size=size, clf=clf, occupancy=occupancy, angle=angle, heading=heading,\n",
    "        anchor=anchor)\n",
    "\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        end_time = time.time()  # End time of the batch\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f'Epoch: {epoch}, batch: {batch_idx}, loss: {loss}, elapsed: {elapsed_time}')\n",
    "        print(f'Batched labels: {batched_labels} and regression targets are: {regression_targets_tensor}')\n",
    "\n",
    "        # Save model every 15 batches:\n",
    "        if batch_idx % 15 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "            }, model_save_path)\n",
    "            print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            continue\n",
    "\n",
    "        # TODO: Add validation here:\n",
    "        model.eval()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx_val, (pseudo_images_val, batched_labels_val) in enumerate(val_loader):\n",
    "\n",
    "                gt_boxes_tensor_val = create_boxes_tensor(batched_labels_val, attributes_idx)\n",
    "        \n",
    "                # Check if gt_boxes_tensor is empty for the current batch\n",
    "                if gt_boxes_tensor_val.nelement() == 0:\n",
    "                    print(f'Encountered an empty element on the batch')\n",
    "                    continue\n",
    "\n",
    "\n",
    "                # Get IoU tensor and regression targets:\n",
    "                iou_tensor_val = anchor.calculate_batch_iou(gt_boxes_tensor_val) \n",
    "                '''IoU tensor (batch_size, n_boxes, num_anchors_x, num_anchors_y)'''\n",
    "\n",
    "                # Regression targets from ground truth labels\n",
    "                regression_targets_tensor_val = anchor.get_regression_targets_tensor(iou_tensor_val, (H,W), threshold=0.5)\n",
    "\n",
    "                # Classification targets:\n",
    "                classification_targets_dict_val = anchor.get_classification_targets(iou_tensor=iou_tensor_val, feature_map_size=(H,W),\n",
    "                                            background_lower_threshold=0.05, background_upper_threshold=0.25)\n",
    "                \n",
    "                loc_val, size_val, clf_val, occupancy_val, angle_val, heading_val = model(pseudo_images_val)\n",
    "    \n",
    "                loss_val = loss_fn(regression_targets=regression_targets_tensor_val, classification_targets_dict=classification_targets_dict_val,\n",
    "                gt_boxes_tensor = gt_boxes_tensor_val, loc=loc_val, size=size_val, clf=clf_val, \n",
    "                occupancy=occupancy_val, angle=angle_val, heading=heading_val, anchor=anchor)\n",
    "\n",
    "                print(f'Validating with batch {batch_idx_val}, got loss: {loss_val}')\n",
    "                \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "model = ...  # Your complete PointPillars model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = PointPillarLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.8)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_data in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform pillarization and forward pass through the model\n",
    "        pillars, coords, ... = pillarize(batch_data)\n",
    "        loc, size, clf, ... = model(pillars, coords)\n",
    "        \n",
    "        # Generate targets using your Anchor class\n",
    "        regression_targets, classification_targets = anchor.generate_targets(batch_data)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(regression_targets, classification_targets, batch_data['gt_boxes'], loc, size, clf, ...)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
