{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Can I can use GPU now? -- True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdb\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import ipdb\n",
    "\n",
    "# Pipelines (a.k.a parts of the Neural Network)\n",
    "from Pipelines.kitti_loader import KITTIDataset\n",
    "from Pipelines.pillarizer import PillarFeatureNet, Pillarization, PseudoImageDataset\n",
    "from Pipelines.backbone import BackBone\n",
    "from Pipelines.detection_head import DetectionHead\n",
    "from Pipelines.anchors import Box2D, Anchor\n",
    "from Pipelines.loss import PointPillarLoss\n",
    "from Pipelines.network import PointPillarsModel\n",
    "\n",
    "from Utils.transformations import transform_to_canvas, transform_to_grid, map_to_img\n",
    "from Utils.iou import calculate_iou\n",
    "from Utils.collate import normalize_annotations\n",
    "from Utils.boxes import create_boxes_tensor # FIXME: Should be in visualization instead\n",
    "\n",
    "# Visualization tools:\n",
    "from Visualization.visz_pointcloud_w_label import plot_point_cloud_with_bboxes_o3d\n",
    "from Visualization.visz_bboxes import visualize_batch_bounding_boxes\n",
    "\n",
    "\n",
    "# Some Neural Network Parameters:\n",
    "AUG_DIM = 9\n",
    "MAX_POINTS_PER_PILLAR = 100\n",
    "MAX_FILLED_PILLARS = 12000\n",
    "X_MIN = 0.0\n",
    "X_MAX = 70.4\n",
    "Y_MIN = -40.0\n",
    "Y_MAX = 40.0\n",
    "Z_MIN = -3.0\n",
    "Z_MAX = 1.0\n",
    "PILLAR_SIZE = (0.16, 0.16)\n",
    "DESIRED_CLASSES = ['Car'] # More classes can be added here\n",
    "SCALE_FACTOR = 1.5\n",
    "H = 500\n",
    "W = 440\n",
    "\n",
    "\n",
    "ANCHORS = torch.tensor([[3.9, 1.6, 1.56, -1, 0], # Anchors as tensor: (height, width, height, z_center, orientation)\n",
    "                       [1.6, 3.9, 1.56, -1, 1.5708],\n",
    "                       [0.8, 0.6, 1.73, -0.6, 0],\n",
    "                       [0.6, 0.8, 1.73, -0.6, 1.5708]]\n",
    "                       )\n",
    "\n",
    "mapped_anchors = ANCHORS.detach().clone()\n",
    "mapped_anchors[:,0:2] /= PILLAR_SIZE[0]\n",
    "\n",
    "\n",
    "# Define a dictionary to map attributes to their indices\n",
    "attributes_idx = {\n",
    "    'norm_x': 7,\n",
    "    'norm_y': 8,\n",
    "    'norm_z': 9,\n",
    "    'norm_h': 10,\n",
    "    'norm_w': 11,\n",
    "    'norm_l': 12,\n",
    "}\n",
    "\n",
    "for anchor_tensor in mapped_anchors: # NOTE: This is regardless of the batch, it is for all the training and testing\n",
    "    anchor = Anchor(width=anchor_tensor[1], height=anchor_tensor[0])\n",
    "    anchor.create_anchor_grid(H,W) # Creates grid\n",
    "    anchor.create_anchors()\n",
    "    break # FIXME: Get rid of this\n",
    "    #anchors_list.append(anchor)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Can I can use GPU now? -- {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create data loaders'''\n",
    "\n",
    "train_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/velodyne_reduced'\n",
    "train_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/label_2'\n",
    "\n",
    "small_train_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne'\n",
    "small_train_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_labels_velodyne'\n",
    "\n",
    "mini_train_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_train_velodyne'\n",
    "mini_train_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_label_velodyne'\n",
    "\n",
    "\n",
    "test_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/testing/velodyne_reduced'\n",
    "\n",
    "\n",
    "# IMPORTANT: Set to CPU for pillarization otherwise, expect GPU memory to overflow\n",
    "device =  torch.device('cpu')\n",
    "\n",
    "\n",
    "# Create a collate function to handle variable-sized labels:\n",
    "def collate_batch(batch):\n",
    "    point_clouds, annotations = zip(*batch)\n",
    "    point_clouds = torch.stack(point_clouds, dim=0)\n",
    "    normalized_annotations = normalize_annotations(annotations, pillar_size=PILLAR_SIZE,\n",
    "        x_lims=(X_MIN, X_MAX), y_lims=(Y_MIN, Y_MAX))\n",
    "    \n",
    "    return point_clouds, normalized_annotations\n",
    "\n",
    "\n",
    "train_set = KITTIDataset(pointcloud_dir=small_train_pointclouds_dir, labels_dir=small_train_labels_dir)\n",
    "        \n",
    "# Create the dataset and DataLoader\n",
    "dataset = PseudoImageDataset(pointcloud_dir=small_train_pointclouds_dir, device=device, kitti_dataset=train_set, aug_dim=AUG_DIM, max_points_in_pillar=MAX_POINTS_PER_PILLAR,\n",
    "                             max_pillars=MAX_FILLED_PILLARS, x_min=X_MIN, y_min=Y_MIN, z_min=Z_MIN, x_max = X_MAX, y_max=Y_MAX,\n",
    "                             z_max = Z_MAX, pillar_size=PILLAR_SIZE)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/Pipelines/kitti_loader.py:50: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.from_numpy(point_cloud)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading point cloud number 9\n",
      "Loading point cloud number 864\n",
      "Loading point cloud number 332\n",
      "Loading point cloud number 516\n",
      "Loss: 24.582162857055664\n",
      "Epoch: 0\n",
      "Batch: 0\n",
      "Loading point cloud number 756\n",
      "Loading point cloud number 211\n",
      "Loading point cloud number 388\n",
      "Loading point cloud number 774\n",
      "Loss: 22.060041427612305\n",
      "Epoch: 0\n",
      "Batch: 1\n",
      "Loading point cloud number 669\n",
      "Loading point cloud number 891\n",
      "Loading point cloud number 428\n",
      "Loading point cloud number 827\n",
      "Loss: 19.510150909423828\n",
      "Epoch: 0\n",
      "Batch: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/train.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/train.ipynb#W2sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBatch: \u001b[39m\u001b[39m{\u001b[39;00mbatch_idx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/train.ipynb#W2sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# Backpropagation\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/train.ipynb#W2sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/train.ipynb#W2sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 7\n",
    "model = PointPillarsModel()\n",
    "loss_fn = PointPillarLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss = 0.0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoch: {epoch}')\n",
    "\n",
    "    # Reset Kitti dataset indexer that retrieves pointclouds and labels:\n",
    "    train_set = KITTIDataset(pointcloud_dir=small_train_pointclouds_dir, labels_dir=small_train_labels_dir)\n",
    "\n",
    "    dataset = PseudoImageDataset(pointcloud_dir=small_train_pointclouds_dir, device=device, kitti_dataset=train_set, aug_dim=AUG_DIM, max_points_in_pillar=MAX_POINTS_PER_PILLAR,\n",
    "                             max_pillars=MAX_FILLED_PILLARS, x_min=X_MIN, y_min=Y_MIN, z_min=Z_MIN, x_max = X_MAX, y_max=Y_MAX,\n",
    "                             z_max = Z_MAX, pillar_size=PILLAR_SIZE)\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_batch)\n",
    "    \n",
    "    '''Enable training mode'''\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (pseudo_images, batched_labels) in enumerate(train_loader):\n",
    "\n",
    "        gt_boxes_tensor = create_boxes_tensor(batched_labels, attributes_idx)\n",
    "        \n",
    "        # Check if gt_boxes_tensor is empty for the current batch\n",
    "        if gt_boxes_tensor.nelement() == 0:\n",
    "            print(f'Encountered an empty element on the batch')\n",
    "            continue\n",
    "        \n",
    "        # Get the roi indices:\n",
    "        roi_indices = anchor.get_ROI_indices(gt_boxes_tensor=gt_boxes_tensor, scale_factor=1.5, \n",
    "                    feature_map_size=(H,W))\n",
    "\n",
    "\n",
    "        # Get IoU tensor and regression targets:\n",
    "        iou_tensor = anchor.calculate_batch_iou(gt_boxes_tensor) \n",
    "        '''IoU tensor (batch_size, n_boxes, num_anchors_x, num_anchors_y)'''\n",
    "\n",
    "        # Regression targets from ground truth labels\n",
    "        regression_targets_tensor = anchor.get_regression_targets_tensor(iou_tensor, (H,W), threshold=0.5)\n",
    "\n",
    "        # Classification targets:\n",
    "        classification_targets_dict = anchor.get_classification_targets(iou_tensor=iou_tensor, feature_map_size=(H,W),\n",
    "                                    background_lower_threshold=0.05, background_upper_threshold=0.25)\n",
    "        \n",
    "        '''Enable gradients'''\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loc, size, clf, occupancy, angle, heading = model(pseudo_images)\n",
    "\n",
    "        \n",
    "        loss = loss_fn(regression_targets=regression_targets_tensor, classification_targets_dict=classification_targets_dict,\n",
    "        gt_boxes_tensor = gt_boxes_tensor, loc=loc, size=size, clf=clf, occupancy=occupancy, angle=angle, heading=heading,\n",
    "        anchor=anchor)\n",
    "\n",
    "        print(f'Loss: {loss}')\n",
    "        print(f'Epoch: {epoch}')\n",
    "        print(f'Batch: {batch_idx}')\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "model = ...  # Your complete PointPillars model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = PointPillarLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.8)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_data in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform pillarization and forward pass through the model\n",
    "        pillars, coords, ... = pillarize(batch_data)\n",
    "        loc, size, clf, ... = model(pillars, coords)\n",
    "        \n",
    "        # Generate targets using your Anchor class\n",
    "        regression_targets, classification_targets = anchor.generate_targets(batch_data)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(regression_targets, classification_targets, batch_data['gt_boxes'], loc, size, clf, ...)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
