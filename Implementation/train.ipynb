{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Can I can use GPU now? -- True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdb\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import ipdb\n",
    "\n",
    "# Pipelines (a.k.a parts of the Neural Network)\n",
    "from Pipelines.kitti_loader import KITTIDataset\n",
    "from Pipelines.pillarizer import PillarFeatureNet, Pillarization, PseudoImageDataset\n",
    "from Pipelines.backbone import BackBone\n",
    "from Pipelines.detection_head import DetectionHead\n",
    "from Pipelines.anchors import Box2D, Anchor\n",
    "#from Pipelines.loss import PointPillarLoss\n",
    "\n",
    "from Utils.transformations import transform_to_canvas, transform_to_grid, map_to_img\n",
    "from Utils.iou import calculate_iou\n",
    "from Utils.collate import normalize_annotations\n",
    "from Utils.boxes import create_boxes_tensor # FIXME: Should be in visualization instead\n",
    "\n",
    "# Visualization tools:\n",
    "from Visualization.visz_pointcloud_w_label import plot_point_cloud_with_bboxes_o3d\n",
    "from Visualization.visz_bboxes import visualize_batch_bounding_boxes\n",
    "\n",
    "\n",
    "# Some Neural Network Parameters:\n",
    "AUG_DIM = 9\n",
    "MAX_POINTS_PER_PILLAR = 100\n",
    "MAX_FILLED_PILLARS = 12000\n",
    "X_MIN = 0.0\n",
    "X_MAX = 70.4\n",
    "Y_MIN = -40.0\n",
    "Y_MAX = 40.0\n",
    "Z_MIN = -3.0\n",
    "Z_MAX = 1.0\n",
    "PILLAR_SIZE = (0.16, 0.16)\n",
    "DESIRED_CLASSES = ['Car'] # More classes can be added here\n",
    "SCALE_FACTOR = 1.5\n",
    "H = 500\n",
    "W = 440\n",
    "\n",
    "\n",
    "ANCHORS = torch.tensor([[3.9, 1.6, 1.56, -1, 0], # Anchors as tensor: (height, width, height, z_center, orientation)\n",
    "                       [1.6, 3.9, 1.56, -1, 1.5708],\n",
    "                       [0.8, 0.6, 1.73, -0.6, 0],\n",
    "                       [0.6, 0.8, 1.73, -0.6, 1.5708]]\n",
    "                       )\n",
    "\n",
    "mapped_anchors = ANCHORS.detach().clone()\n",
    "mapped_anchors[:,0:2] /= PILLAR_SIZE[0]\n",
    "\n",
    "\n",
    "# Define a dictionary to map attributes to their indices\n",
    "attributes_idx = {\n",
    "    'norm_x': 7,\n",
    "    'norm_y': 8,\n",
    "    'norm_z': 9,\n",
    "    'norm_h': 10,\n",
    "    'norm_w': 11,\n",
    "    'norm_l': 12,\n",
    "}\n",
    "\n",
    "for anchor_tensor in mapped_anchors: # NOTE: This is regardless of the batch, it is for all the training and testing\n",
    "    anchor = Anchor(width=anchor_tensor[1], height=anchor_tensor[0])\n",
    "    anchor.create_anchor_grid(H,W) # Creates grid\n",
    "    anchor.create_anchors()\n",
    "    break # FIXME: Get rid of this\n",
    "    #anchors_list.append(anchor)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Can I can use GPU now? -- {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create data loaders'''\n",
    "\n",
    "train_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/velodyne_reduced'\n",
    "train_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/label_2'\n",
    "\n",
    "mini_train_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_train_velodyne'\n",
    "mini_train_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_label_velodyne'\n",
    "\n",
    "\n",
    "\n",
    "test_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/testing/velodyne_reduced'\n",
    "\n",
    "\n",
    "# IMPORTANT: Set to CPU for pillarization otherwise, expect GPU memory to overflow\n",
    "device =  torch.device('cpu')\n",
    "\n",
    "\n",
    "# Create a collate function to handle variable-sized labels:\n",
    "def collate_batch(batch):\n",
    "    point_clouds, annotations = zip(*batch)\n",
    "    point_clouds = torch.stack(point_clouds, dim=0)\n",
    "    normalized_annotations = normalize_annotations(annotations, pillar_size=PILLAR_SIZE,\n",
    "        x_lims=(X_MIN, X_MAX), y_lims=(Y_MIN, Y_MAX))\n",
    "    \n",
    "    return point_clouds, normalized_annotations\n",
    "\n",
    "\n",
    "train_set = KITTIDataset(pointcloud_dir=mini_train_pointclouds_dir, labels_dir=mini_train_labels_dir)\n",
    "        \n",
    "# Create the dataset and DataLoader\n",
    "dataset = PseudoImageDataset(pointcloud_dir=train_pointclouds_dir, device=device, kitti_dataset=train_set, aug_dim=AUG_DIM, max_points_in_pillar=MAX_POINTS_PER_PILLAR,\n",
    "                             max_pillars=MAX_FILLED_PILLARS, x_min=X_MIN, y_min=Y_MIN, z_min=Z_MIN, x_max = X_MAX, y_max=Y_MAX,\n",
    "                             z_max = Z_MAX, pillar_size=PILLAR_SIZE)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=collate_batch) # FIXME: Set batch to 4 again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_train_velodyne/000008.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/Pipelines/kitti_loader.py:50: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.from_numpy(point_cloud)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading point cloud number 0\n",
      "Loss: 20.97913360595703\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_train_velodyne/000007.bin\n",
      "Loading point cloud number 1\n",
      "Loss: 38.3955192565918\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_train_velodyne/000008.bin\n",
      "Loading point cloud number 0\n",
      "Loss: 20.801647186279297\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_train_velodyne/000007.bin\n",
      "Loading point cloud number 1\n",
      "Loss: 38.37483215332031\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_train_velodyne/000008.bin\n",
      "Loading point cloud number 0\n",
      "Loss: 20.804847717285156\n",
      "File loaded: /home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_train_velodyne/000007.bin\n",
      "Loading point cloud number 1\n",
      "Loss: 38.3310546875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class PointPillarLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, beta_loc = 2.0, beta_cls = 1.0):\n",
    "        super(PointPillarLoss, self).__init__()\n",
    "        self.smooth_l1_loss = nn.SmoothL1Loss()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.beta_cls = beta_cls\n",
    "        self.beta_loc = beta_loc\n",
    "\n",
    "\n",
    "    def forward(self, regression_targets, classification_targets_dict, \n",
    "                gt_boxes_tensor, loc, size, clf, occupancy, angle, heading, anchor):\n",
    "        \n",
    "        '''\n",
    "        Inputs: \n",
    "        loc -- size (batch_size, n_anchors, 3, H, W)\n",
    "        size -- size (batch_size, n_anchors, 3, H, W) \n",
    "        clf -- size (batch_size, n_anchors, 3, H, W)\n",
    "        regression_targets -- tensor of size (batch_size, n_boxes, 2) with the indices of the best matching anchors\n",
    "        gt_boxes_tensor -- size (bs, n_boxes, 4)\n",
    "        '''\n",
    "\n",
    "        da = torch.sqrt(anchor.width**2 + anchor.height**2)\n",
    "\n",
    "        # Initialize the predictions\n",
    "        batch_size, n_boxes = regression_targets.shape[:2]\n",
    "        x_pred = torch.zeros(batch_size, n_boxes, dtype=loc.dtype)\n",
    "        y_pred = torch.zeros(batch_size, n_boxes, dtype=loc.dtype)\n",
    "        dx_tensor = torch.zeros(batch_size, n_boxes, dtype=loc.dtype)\n",
    "        dy_tensor = torch.zeros(batch_size, n_boxes, dtype=loc.dtype)\n",
    "\n",
    "        # Regression loss:\n",
    "        car_focal_loss = 0.0\n",
    "        for b in range(batch_size):\n",
    "            for n in range(n_boxes):\n",
    "                x_idx = regression_targets[b, n, 0].long()  # Ensure the indices are long type\n",
    "                y_idx = regression_targets[b, n, 1].long()  # Ensure the indices are long type\n",
    "                x_pred[b, n] = loc[b, 0, 0, y_idx, x_idx]  # Indexing y first as it corresponds to H dimension\n",
    "                y_pred[b, n] = loc[b, 0, 1, y_idx, x_idx]  # Indexing y first as it corresponds to H dimension\n",
    "                x_gt = gt_boxes_tensor[b, n, 0] + (gt_boxes_tensor[b, n, 2] - gt_boxes_tensor[b, n, 0])/2\n",
    "                y_gt = gt_boxes_tensor[b, n, 1] - (gt_boxes_tensor[b, n, 3] - gt_boxes_tensor[b, n, 1])/2\n",
    "                dx_tensor[b, n] = (x_gt - x_pred[b,n]) / da \n",
    "                dy_tensor[b, n] = (y_gt - y_pred[b,n]) / da \n",
    "                car_prob = clf[b, 0, 1, y_idx, x_idx]\n",
    "                car_focal_loss += -torch.log(car_prob)*self.alpha*(1 - car_prob)**self.gamma\n",
    "\n",
    "        if batch_size*n_boxes != 0.0:\n",
    "            car_focal_loss /= batch_size*n_boxes\n",
    "        else: \n",
    "            print(f'Division by zero encountered on cars!')\n",
    "            car_focal_loss = 0.0\n",
    "\n",
    "        \n",
    "        # Classification loss:\n",
    "        '''background probs -- dict{batch: prob_loss}'''\n",
    "        background_focal_loss = 0.0\n",
    "        n_classification_target = 0\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for n_target, cls_target in enumerate(classification_targets_dict[b]):\n",
    "                x_idx = classification_targets_dict[b][n_target][1] #(n_box, x, y)\n",
    "                y_idx = classification_targets_dict[b][n_target][2]\n",
    "                '''clf -- size (batch_size, n_anchors, 3, H, W)'''\n",
    "                clf_val = clf[b][0][0][y_idx][x_idx]\n",
    "                # Apply focal loss\n",
    "                background_focal_loss += -torch.log(clf_val)*self.alpha*(1 - clf_val)**self.gamma\n",
    "                n_classification_target += 1\n",
    "\n",
    "        if batch_size*n_boxes != 0.0:\n",
    "            background_focal_loss /= n_classification_target\n",
    "        else:\n",
    "            background_focal_loss = 0.0\n",
    "            print(f'Division by zero encountered on background!')              \n",
    "\n",
    "        # Calculate regression loss:\n",
    "        loc_loss_x = self.smooth_l1_loss(dx_tensor, torch.zeros_like(dx_tensor))\n",
    "        loc_loss_y = self.smooth_l1_loss(dy_tensor, torch.zeros_like(dx_tensor))\n",
    "\n",
    "        # Calculate classification loss:\n",
    "        total_loc_loss = loc_loss_x + loc_loss_y\n",
    "\n",
    "        # Calculate regression loss:\n",
    "        total_loss = self.beta_loc*total_loc_loss + self.beta_cls*(background_focal_loss + car_focal_loss)\n",
    "\n",
    "\n",
    "        return total_loss\n",
    "    \n",
    "\n",
    "'''Set up the neural network for training'''\n",
    "\n",
    "class PointPillarsModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointPillarsModel, self).__init__()\n",
    "        self.backbone = BackBone(in_channels=64, out_channels=64, device=torch.device('cuda'))\n",
    "        self.detection_head = DetectionHead(in_channels=384, grid_size_x=500, grid_size_y=440, num_anchors=1, \n",
    "                num_classes=2, device=torch.device('cuda'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through backbone and detection head\n",
    "        features = self.backbone(x)\n",
    "        loc, size, clf, occupancy, angle, heading = self.detection_head(features)\n",
    "        return loc, size, clf, occupancy, angle, heading\n",
    "\n",
    "\n",
    "'''\n",
    "# Declare model:\n",
    "backbone = BackBone(in_channels=64, out_channels=64, device=torch.device('cuda'))\n",
    "\n",
    "detection_head = DetectionHead(device=torch.device('cuda'), in_channels=384, grid_size_x=500, \n",
    "                        grid_size_y=440, num_anchors=1, num_classes=2) \n",
    "\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)'''\n",
    "\n",
    "n_epochs = 3\n",
    "model = PointPillarsModel()\n",
    "loss_fn = PointPillarLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss = 0.0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_set = KITTIDataset(pointcloud_dir=mini_train_pointclouds_dir, labels_dir=mini_train_labels_dir)\n",
    "        \n",
    "    # Create the dataset and DataLoader\n",
    "\n",
    "    dataset = PseudoImageDataset(pointcloud_dir=mini_train_pointclouds_dir, device=device, kitti_dataset=train_set, aug_dim=AUG_DIM, max_points_in_pillar=MAX_POINTS_PER_PILLAR,\n",
    "                             max_pillars=MAX_FILLED_PILLARS, x_min=X_MIN, y_min=Y_MIN, z_min=Z_MIN, x_max = X_MAX, y_max=Y_MAX,\n",
    "                             z_max = Z_MAX, pillar_size=PILLAR_SIZE)\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=2, shuffle=False, collate_fn=collate_batch)\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (pseudo_images, batched_labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        gt_boxes_tensor = create_boxes_tensor(batched_labels, attributes_idx)\n",
    "\n",
    "        # Check if gt_boxes_tensor is empty for the current batch\n",
    "        if gt_boxes_tensor.nelement() == 0:\n",
    "            print(f\"No ground truth boxes present in batch {batch_idx}. Skipping.\")\n",
    "            continue  # Skip this batch\n",
    "        \n",
    "        # Get the roi indices:\n",
    "        roi_indices = anchor.get_ROI_indices(gt_boxes_tensor=gt_boxes_tensor, scale_factor=1.5, \n",
    "                    feature_map_size=(H,W))\n",
    "\n",
    "\n",
    "        # Get IoU tensor and regression targets:\n",
    "        iou_tensor = anchor.calculate_batch_iou(gt_boxes_tensor) \n",
    "        '''IoU tensor (batch_size, n_boxes, num_anchors_x, num_anchors_y)'''\n",
    "\n",
    "\n",
    "        regression_targets_dict = anchor.get_regression_targets(iou_tensor, (H, W), threshold=0.5)\n",
    "        '''A dictionary with keys as batch indices and values as lists of\n",
    "        (box_index, feature_map_x_index, feature_map_y_index'''\n",
    "\n",
    "\n",
    "        regression_targets_tensor = anchor.get_regression_targets_tensor(iou_tensor, (H,W), threshold=0.5)\n",
    "\n",
    "\n",
    "        classification_targets_dict = anchor.get_classification_targets(iou_tensor=iou_tensor, feature_map_size=(H,W),\n",
    "                                    background_lower_threshold=0.05, background_upper_threshold=0.25)\n",
    "        \n",
    "\n",
    "        loc, size, clf, occupancy, angle, heading = model(pseudo_images)\n",
    "\n",
    "        \n",
    "        loss = loss_fn(regression_targets=regression_targets_tensor, classification_targets_dict=classification_targets_dict,\n",
    "        gt_boxes_tensor = gt_boxes_tensor, loc=loc, size=size, clf=clf, occupancy=occupancy, angle=angle, heading=heading,\n",
    "        anchor=anchor)\n",
    "\n",
    "        print(f'Loss: {loss}')\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "model = ...  # Your complete PointPillars model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = PointPillarLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.8)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_data in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform pillarization and forward pass through the model\n",
    "        pillars, coords, ... = pillarize(batch_data)\n",
    "        loc, size, clf, ... = model(pillars, coords)\n",
    "        \n",
    "        # Generate targets using your Anchor class\n",
    "        regression_targets, classification_targets = anchor.generate_targets(batch_data)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(regression_targets, classification_targets, batch_data['gt_boxes'], loc, size, clf, ...)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
