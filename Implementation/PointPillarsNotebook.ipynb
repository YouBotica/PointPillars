{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42732c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I can use GPU now? -- True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdb\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import ipdb\n",
    "\n",
    "print(f'Can I can use GPU now? -- {torch.cuda.is_available()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dc7870",
   "metadata": {},
   "source": [
    "Load data from the KITTI dataset and perform train-test split:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b209d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KITTIDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the point clouds.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.files = [f for f in os.listdir(root_dir) if os.path.isfile(os.path.join(root_dir, f))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        point_cloud_path = os.path.join(self.root_dir, self.files[idx])\n",
    "        point_cloud = self.load_point_cloud_from_bin(point_cloud_path)\n",
    "        return point_cloud\n",
    "    \n",
    "    def load_point_cloud_from_bin(self, bin_path):\n",
    "        with open(bin_path, 'rb') as f:\n",
    "            content = f.read()\n",
    "            point_cloud = np.frombuffer(content, dtype=np.float32)\n",
    "            point_cloud = point_cloud.reshape(-1, 4)  # KITTI point clouds are (x, y, z, intensity)\n",
    "        return torch.from_numpy(point_cloud)\n",
    "        \n",
    "\n",
    "train_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/velodyne_reduced'\n",
    "test_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/testing/velodyne_reduced'\n",
    "\n",
    "train_set = KITTIDataset(root_dir=train_dir)\n",
    "test_set = KITTIDataset(root_dir=test_dir)\n",
    "        \n",
    "        \n",
    "#batched_train_set = DataLoader(train_set, batch_size=4, shuffle=False)\n",
    "#batched_test_set = DataLoader(test_set, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are we getting labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'Car 0.00 1 2.88 510.73 157.13 746.01 251.35 1.46 1.53 3.80 0.32 1.09 12.29 2.90\\\\nCar 0.00 0 -3.02 195.37 146.41 471.42 252.08 1.53 1.40 3.94 -4.24 1.02 11.45 2.92\\\\nCar 0.78 0 -2.60 0.00 148.79 85.45 256.99 1.48 1.55 3.29 -9.75 1.06 10.14 2.93\\\\nCyclist 0.00 0 2.35 585.64 152.87 724.54 307.90 1.57 0.52 1.66 0.56 1.29 7.92 2.42\\\\n'\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_path = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/label_2'\n",
    "label_files = [f for f in os.listdir(label_path) if os.path.isfile(os.path.join(label_path, f))]\n",
    "\n",
    "label_path = os.path.join(label_path, label_files[0]) # A single sample for now:\n",
    "with open(label_path, 'rb') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "str(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/PointPillarsNotebook.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/PointPillarsNotebook.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m content\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "content.split('\\\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['007147.txt',\n",
       " '007418.txt',\n",
       " '002750.txt',\n",
       " '004214.txt',\n",
       " '002831.txt',\n",
       " '004302.txt',\n",
       " '001829.txt',\n",
       " '006076.txt',\n",
       " '005841.txt',\n",
       " '005734.txt',\n",
       " '000476.txt',\n",
       " '006701.txt',\n",
       " '004271.txt',\n",
       " '005051.txt',\n",
       " '006779.txt',\n",
       " '003250.txt',\n",
       " '003466.txt',\n",
       " '000500.txt',\n",
       " '000592.txt',\n",
       " '005167.txt',\n",
       " '003350.txt',\n",
       " '004029.txt',\n",
       " '001240.txt',\n",
       " '004919.txt',\n",
       " '001345.txt',\n",
       " '006526.txt',\n",
       " '004477.txt',\n",
       " '005115.txt',\n",
       " '004017.txt',\n",
       " '003114.txt',\n",
       " '006055.txt',\n",
       " '004412.txt',\n",
       " '004207.txt',\n",
       " '007397.txt',\n",
       " '004108.txt',\n",
       " '003306.txt',\n",
       " '004579.txt',\n",
       " '003919.txt',\n",
       " '001387.txt',\n",
       " '002797.txt',\n",
       " '005019.txt',\n",
       " '002459.txt',\n",
       " '002400.txt',\n",
       " '006512.txt',\n",
       " '004462.txt',\n",
       " '006627.txt',\n",
       " '001816.txt',\n",
       " '000808.txt',\n",
       " '007004.txt',\n",
       " '006531.txt',\n",
       " '006399.txt',\n",
       " '003471.txt',\n",
       " '001349.txt',\n",
       " '006179.txt',\n",
       " '006415.txt',\n",
       " '005731.txt',\n",
       " '001330.txt',\n",
       " '006705.txt',\n",
       " '000960.txt',\n",
       " '005791.txt',\n",
       " '000565.txt',\n",
       " '003263.txt',\n",
       " '005074.txt',\n",
       " '004998.txt',\n",
       " '003305.txt',\n",
       " '001616.txt',\n",
       " '006262.txt',\n",
       " '001162.txt',\n",
       " '001039.txt',\n",
       " '000265.txt',\n",
       " '007330.txt',\n",
       " '006395.txt',\n",
       " '000087.txt',\n",
       " '002971.txt',\n",
       " '003511.txt',\n",
       " '000715.txt',\n",
       " '000117.txt',\n",
       " '006498.txt',\n",
       " '003713.txt',\n",
       " '003035.txt',\n",
       " '001803.txt',\n",
       " '003922.txt',\n",
       " '005213.txt',\n",
       " '002273.txt',\n",
       " '000837.txt',\n",
       " '006160.txt',\n",
       " '004642.txt',\n",
       " '000795.txt',\n",
       " '002725.txt',\n",
       " '003295.txt',\n",
       " '003417.txt',\n",
       " '006095.txt',\n",
       " '003069.txt',\n",
       " '003690.txt',\n",
       " '004082.txt',\n",
       " '005476.txt',\n",
       " '003940.txt',\n",
       " '006423.txt',\n",
       " '000732.txt',\n",
       " '001242.txt',\n",
       " '005647.txt',\n",
       " '005700.txt',\n",
       " '006971.txt',\n",
       " '003047.txt',\n",
       " '001949.txt',\n",
       " '007155.txt',\n",
       " '000162.txt',\n",
       " '003565.txt',\n",
       " '002044.txt',\n",
       " '001904.txt',\n",
       " '007410.txt',\n",
       " '000991.txt',\n",
       " '003113.txt',\n",
       " '003181.txt',\n",
       " '000637.txt',\n",
       " '006993.txt',\n",
       " '005152.txt',\n",
       " '006870.txt',\n",
       " '000995.txt',\n",
       " '006611.txt',\n",
       " '001455.txt',\n",
       " '006753.txt',\n",
       " '000366.txt',\n",
       " '006358.txt',\n",
       " '000952.txt',\n",
       " '000116.txt',\n",
       " '004562.txt',\n",
       " '001058.txt',\n",
       " '000663.txt',\n",
       " '006504.txt',\n",
       " '002277.txt',\n",
       " '000394.txt',\n",
       " '005368.txt',\n",
       " '003487.txt',\n",
       " '004281.txt',\n",
       " '003152.txt',\n",
       " '004262.txt',\n",
       " '004889.txt',\n",
       " '005693.txt',\n",
       " '003206.txt',\n",
       " '000490.txt',\n",
       " '005008.txt',\n",
       " '002896.txt',\n",
       " '005811.txt',\n",
       " '003982.txt',\n",
       " '000844.txt',\n",
       " '000884.txt',\n",
       " '006276.txt',\n",
       " '003606.txt',\n",
       " '007049.txt',\n",
       " '003266.txt',\n",
       " '003025.txt',\n",
       " '000759.txt',\n",
       " '006806.txt',\n",
       " '004713.txt',\n",
       " '001133.txt',\n",
       " '001752.txt',\n",
       " '005503.txt',\n",
       " '005697.txt',\n",
       " '006284.txt',\n",
       " '003134.txt',\n",
       " '001231.txt',\n",
       " '000190.txt',\n",
       " '003986.txt',\n",
       " '004434.txt',\n",
       " '006034.txt',\n",
       " '005127.txt',\n",
       " '004865.txt',\n",
       " '004537.txt',\n",
       " '005175.txt',\n",
       " '005565.txt',\n",
       " '003090.txt',\n",
       " '005455.txt',\n",
       " '002280.txt',\n",
       " '000159.txt',\n",
       " '001083.txt',\n",
       " '005950.txt',\n",
       " '001519.txt',\n",
       " '005000.txt',\n",
       " '001608.txt',\n",
       " '001343.txt',\n",
       " '000993.txt',\n",
       " '001834.txt',\n",
       " '000051.txt',\n",
       " '006912.txt',\n",
       " '000315.txt',\n",
       " '006741.txt',\n",
       " '007213.txt',\n",
       " '006883.txt',\n",
       " '007261.txt',\n",
       " '003421.txt',\n",
       " '001281.txt',\n",
       " '002791.txt',\n",
       " '001368.txt',\n",
       " '003681.txt',\n",
       " '004569.txt',\n",
       " '006670.txt',\n",
       " '005134.txt',\n",
       " '002699.txt',\n",
       " '001660.txt',\n",
       " '006763.txt',\n",
       " '001103.txt',\n",
       " '002659.txt',\n",
       " '000504.txt',\n",
       " '001712.txt',\n",
       " '001552.txt',\n",
       " '005744.txt',\n",
       " '001922.txt',\n",
       " '000718.txt',\n",
       " '000161.txt',\n",
       " '001095.txt',\n",
       " '007073.txt',\n",
       " '001757.txt',\n",
       " '003553.txt',\n",
       " '002343.txt',\n",
       " '007348.txt',\n",
       " '001600.txt',\n",
       " '005750.txt',\n",
       " '007166.txt',\n",
       " '001574.txt',\n",
       " '000272.txt',\n",
       " '001338.txt',\n",
       " '001592.txt',\n",
       " '003245.txt',\n",
       " '005844.txt',\n",
       " '005619.txt',\n",
       " '001012.txt',\n",
       " '007361.txt',\n",
       " '006362.txt',\n",
       " '003768.txt',\n",
       " '007414.txt',\n",
       " '002945.txt',\n",
       " '003297.txt',\n",
       " '003064.txt',\n",
       " '005823.txt',\n",
       " '005061.txt',\n",
       " '001835.txt',\n",
       " '002597.txt',\n",
       " '003469.txt',\n",
       " '005510.txt',\n",
       " '004299.txt',\n",
       " '007346.txt',\n",
       " '000024.txt',\n",
       " '003886.txt',\n",
       " '001327.txt',\n",
       " '002816.txt',\n",
       " '000785.txt',\n",
       " '006814.txt',\n",
       " '002378.txt',\n",
       " '001989.txt',\n",
       " '002720.txt',\n",
       " '006680.txt',\n",
       " '000608.txt',\n",
       " '003504.txt',\n",
       " '004183.txt',\n",
       " '001748.txt',\n",
       " '005732.txt',\n",
       " '004949.txt',\n",
       " '002665.txt',\n",
       " '002596.txt',\n",
       " '004781.txt',\n",
       " '005881.txt',\n",
       " '005218.txt',\n",
       " '005905.txt',\n",
       " '003990.txt',\n",
       " '003954.txt',\n",
       " '004464.txt',\n",
       " '001114.txt',\n",
       " '003142.txt',\n",
       " '001531.txt',\n",
       " '002821.txt',\n",
       " '005735.txt',\n",
       " '005703.txt',\n",
       " '004136.txt',\n",
       " '001355.txt',\n",
       " '002878.txt',\n",
       " '004463.txt',\n",
       " '000888.txt',\n",
       " '007324.txt',\n",
       " '000814.txt',\n",
       " '007135.txt',\n",
       " '007432.txt',\n",
       " '006014.txt',\n",
       " '006538.txt',\n",
       " '005270.txt',\n",
       " '004543.txt',\n",
       " '006282.txt',\n",
       " '001023.txt',\n",
       " '001518.txt',\n",
       " '003052.txt',\n",
       " '002199.txt',\n",
       " '000791.txt',\n",
       " '002533.txt',\n",
       " '002716.txt',\n",
       " '000626.txt',\n",
       " '002425.txt',\n",
       " '004255.txt',\n",
       " '005442.txt',\n",
       " '002706.txt',\n",
       " '002421.txt',\n",
       " '005793.txt',\n",
       " '001498.txt',\n",
       " '000779.txt',\n",
       " '006039.txt',\n",
       " '006795.txt',\n",
       " '005725.txt',\n",
       " '001772.txt',\n",
       " '005913.txt',\n",
       " '001605.txt',\n",
       " '002282.txt',\n",
       " '006810.txt',\n",
       " '002580.txt',\n",
       " '001086.txt',\n",
       " '001643.txt',\n",
       " '006136.txt',\n",
       " '005576.txt',\n",
       " '000914.txt',\n",
       " '005951.txt',\n",
       " '000695.txt',\n",
       " '001795.txt',\n",
       " '000168.txt',\n",
       " '006674.txt',\n",
       " '001729.txt',\n",
       " '004637.txt',\n",
       " '004373.txt',\n",
       " '004234.txt',\n",
       " '005290.txt',\n",
       " '005025.txt',\n",
       " '006256.txt',\n",
       " '006747.txt',\n",
       " '007087.txt',\n",
       " '001770.txt',\n",
       " '001746.txt',\n",
       " '004962.txt',\n",
       " '000656.txt',\n",
       " '006264.txt',\n",
       " '007173.txt',\n",
       " '002161.txt',\n",
       " '005909.txt',\n",
       " '001200.txt',\n",
       " '001875.txt',\n",
       " '006744.txt',\n",
       " '002591.txt',\n",
       " '002621.txt',\n",
       " '004342.txt',\n",
       " '006891.txt',\n",
       " '005884.txt',\n",
       " '005804.txt',\n",
       " '000326.txt',\n",
       " '006730.txt',\n",
       " '000263.txt',\n",
       " '002174.txt',\n",
       " '005635.txt',\n",
       " '001040.txt',\n",
       " '004566.txt',\n",
       " '001356.txt',\n",
       " '003400.txt',\n",
       " '001138.txt',\n",
       " '001227.txt',\n",
       " '004527.txt',\n",
       " '005358.txt',\n",
       " '001686.txt',\n",
       " '005855.txt',\n",
       " '004657.txt',\n",
       " '007402.txt',\n",
       " '005544.txt',\n",
       " '005795.txt',\n",
       " '007340.txt',\n",
       " '006379.txt',\n",
       " '002671.txt',\n",
       " '006734.txt',\n",
       " '005936.txt',\n",
       " '007390.txt',\n",
       " '003615.txt',\n",
       " '002340.txt',\n",
       " '005470.txt',\n",
       " '005625.txt',\n",
       " '002822.txt',\n",
       " '005902.txt',\n",
       " '001375.txt',\n",
       " '001615.txt',\n",
       " '001841.txt',\n",
       " '002664.txt',\n",
       " '002217.txt',\n",
       " '006775.txt',\n",
       " '002641.txt',\n",
       " '005535.txt',\n",
       " '003533.txt',\n",
       " '005395.txt',\n",
       " '007328.txt',\n",
       " '006220.txt',\n",
       " '001544.txt',\n",
       " '002719.txt',\n",
       " '004742.txt',\n",
       " '002914.txt',\n",
       " '002477.txt',\n",
       " '002507.txt',\n",
       " '006175.txt',\n",
       " '001899.txt',\n",
       " '002148.txt',\n",
       " '001291.txt',\n",
       " '003649.txt',\n",
       " '002281.txt',\n",
       " '001106.txt',\n",
       " '000010.txt',\n",
       " '007422.txt',\n",
       " '003462.txt',\n",
       " '003349.txt',\n",
       " '004254.txt',\n",
       " '005301.txt',\n",
       " '002654.txt',\n",
       " '003086.txt',\n",
       " '003667.txt',\n",
       " '006351.txt',\n",
       " '007381.txt',\n",
       " '004633.txt',\n",
       " '005769.txt',\n",
       " '001102.txt',\n",
       " '000437.txt',\n",
       " '004848.txt',\n",
       " '007059.txt',\n",
       " '000050.txt',\n",
       " '006070.txt',\n",
       " '002611.txt',\n",
       " '001126.txt',\n",
       " '004767.txt',\n",
       " '003072.txt',\n",
       " '005328.txt',\n",
       " '000453.txt',\n",
       " '002575.txt',\n",
       " '005160.txt',\n",
       " '003284.txt',\n",
       " '001555.txt',\n",
       " '001894.txt',\n",
       " '004884.txt',\n",
       " '002101.txt',\n",
       " '003975.txt',\n",
       " '006144.txt',\n",
       " '004861.txt',\n",
       " '000422.txt',\n",
       " '003634.txt',\n",
       " '003175.txt',\n",
       " '006704.txt',\n",
       " '005103.txt',\n",
       " '004823.txt',\n",
       " '001891.txt',\n",
       " '006545.txt',\n",
       " '005895.txt',\n",
       " '004450.txt',\n",
       " '005604.txt',\n",
       " '001480.txt',\n",
       " '000773.txt',\n",
       " '005963.txt',\n",
       " '002738.txt',\n",
       " '006133.txt',\n",
       " '001376.txt',\n",
       " '006151.txt',\n",
       " '006197.txt',\n",
       " '003275.txt',\n",
       " '004568.txt',\n",
       " '006057.txt',\n",
       " '006330.txt',\n",
       " '000133.txt',\n",
       " '004873.txt',\n",
       " '000358.txt',\n",
       " '005343.txt',\n",
       " '006409.txt',\n",
       " '003271.txt',\n",
       " '002240.txt',\n",
       " '003104.txt',\n",
       " '005992.txt',\n",
       " '006495.txt',\n",
       " '000534.txt',\n",
       " '004127.txt',\n",
       " '005086.txt',\n",
       " '006367.txt',\n",
       " '005325.txt',\n",
       " '004133.txt',\n",
       " '003804.txt',\n",
       " '005464.txt',\n",
       " '004599.txt',\n",
       " '004341.txt',\n",
       " '006581.txt',\n",
       " '007247.txt',\n",
       " '006768.txt',\n",
       " '001266.txt',\n",
       " '005405.txt',\n",
       " '002925.txt',\n",
       " '003209.txt',\n",
       " '000935.txt',\n",
       " '004163.txt',\n",
       " '002733.txt',\n",
       " '003557.txt',\n",
       " '006678.txt',\n",
       " '007464.txt',\n",
       " '001830.txt',\n",
       " '005588.txt',\n",
       " '002944.txt',\n",
       " '001915.txt',\n",
       " '003159.txt',\n",
       " '001839.txt',\n",
       " '002079.txt',\n",
       " '004406.txt',\n",
       " '002976.txt',\n",
       " '000371.txt',\n",
       " '005988.txt',\n",
       " '006735.txt',\n",
       " '004991.txt',\n",
       " '002514.txt',\n",
       " '005437.txt',\n",
       " '000046.txt',\n",
       " '002807.txt',\n",
       " '002117.txt',\n",
       " '001959.txt',\n",
       " '002424.txt',\n",
       " '003541.txt',\n",
       " '000944.txt',\n",
       " '004179.txt',\n",
       " '003310.txt',\n",
       " '004222.txt',\n",
       " '005675.txt',\n",
       " '006663.txt',\n",
       " '007376.txt',\n",
       " '002737.txt',\n",
       " '000519.txt',\n",
       " '007341.txt',\n",
       " '005244.txt',\n",
       " '003286.txt',\n",
       " '007311.txt',\n",
       " '002628.txt',\n",
       " '001360.txt',\n",
       " '005064.txt',\n",
       " '000032.txt',\n",
       " '000985.txt',\n",
       " '006644.txt',\n",
       " '007332.txt',\n",
       " '006543.txt',\n",
       " '004722.txt',\n",
       " '004202.txt',\n",
       " '004545.txt',\n",
       " '007226.txt',\n",
       " '005071.txt',\n",
       " '005347.txt',\n",
       " '002938.txt',\n",
       " '000693.txt',\n",
       " '004618.txt',\n",
       " '001515.txt',\n",
       " '004442.txt',\n",
       " '002693.txt',\n",
       " '000111.txt',\n",
       " '004771.txt',\n",
       " '005329.txt',\n",
       " '006547.txt',\n",
       " '001125.txt',\n",
       " '000434.txt',\n",
       " '005069.txt',\n",
       " '003221.txt',\n",
       " '007163.txt',\n",
       " '000403.txt',\n",
       " '007125.txt',\n",
       " '003830.txt',\n",
       " '001586.txt',\n",
       " '005680.txt',\n",
       " '003812.txt',\n",
       " '001209.txt',\n",
       " '006125.txt',\n",
       " '005705.txt',\n",
       " '001247.txt',\n",
       " '007433.txt',\n",
       " '001823.txt',\n",
       " '003806.txt',\n",
       " '007056.txt',\n",
       " '004864.txt',\n",
       " '004910.txt',\n",
       " '000797.txt',\n",
       " '006911.txt',\n",
       " '001388.txt',\n",
       " '005869.txt',\n",
       " '003506.txt',\n",
       " '000089.txt',\n",
       " '002360.txt',\n",
       " '002151.txt',\n",
       " '001865.txt',\n",
       " '006981.txt',\n",
       " '001407.txt',\n",
       " '006542.txt',\n",
       " '006291.txt',\n",
       " '005482.txt',\n",
       " '002902.txt',\n",
       " '005525.txt',\n",
       " '002165.txt',\n",
       " '005491.txt',\n",
       " '001775.txt',\n",
       " '000948.txt',\n",
       " '000679.txt',\n",
       " '000389.txt',\n",
       " '005505.txt',\n",
       " '000683.txt',\n",
       " '001425.txt',\n",
       " '003822.txt',\n",
       " '001556.txt',\n",
       " '000303.txt',\n",
       " '004815.txt',\n",
       " '001440.txt',\n",
       " '001533.txt',\n",
       " '007243.txt',\n",
       " '001156.txt',\n",
       " '000275.txt',\n",
       " '005126.txt',\n",
       " '006577.txt',\n",
       " '004030.txt',\n",
       " '001957.txt',\n",
       " '001863.txt',\n",
       " '006132.txt',\n",
       " '001301.txt',\n",
       " '000185.txt',\n",
       " '001985.txt',\n",
       " '001087.txt',\n",
       " '002028.txt',\n",
       " '000821.txt',\n",
       " '007308.txt',\n",
       " '002731.txt',\n",
       " '000962.txt',\n",
       " '001910.txt',\n",
       " '003861.txt',\n",
       " '007153.txt',\n",
       " '005877.txt',\n",
       " '004348.txt',\n",
       " '005193.txt',\n",
       " '004780.txt',\n",
       " '002073.txt',\n",
       " '001450.txt',\n",
       " '006713.txt',\n",
       " '003330.txt',\n",
       " '000531.txt',\n",
       " '002182.txt',\n",
       " '002464.txt',\n",
       " '001998.txt',\n",
       " '002696.txt',\n",
       " '002013.txt',\n",
       " '003658.txt',\n",
       " '000099.txt',\n",
       " '004390.txt',\n",
       " '000755.txt',\n",
       " '002242.txt',\n",
       " '007090.txt',\n",
       " '003092.txt',\n",
       " '002965.txt',\n",
       " '000924.txt',\n",
       " '006022.txt',\n",
       " '002652.txt',\n",
       " '005772.txt',\n",
       " '004274.txt',\n",
       " '005250.txt',\n",
       " '005484.txt',\n",
       " '003061.txt',\n",
       " '000929.txt',\n",
       " '007233.txt',\n",
       " '006332.txt',\n",
       " '007387.txt',\n",
       " '002086.txt',\n",
       " '000689.txt',\n",
       " '006889.txt',\n",
       " '004737.txt',\n",
       " '000981.txt',\n",
       " '003668.txt',\n",
       " '003168.txt',\n",
       " '002877.txt',\n",
       " '002136.txt',\n",
       " '005424.txt',\n",
       " '002548.txt',\n",
       " '005927.txt',\n",
       " '005592.txt',\n",
       " '002130.txt',\n",
       " '004953.txt',\n",
       " '006278.txt',\n",
       " '004611.txt',\n",
       " '001940.txt',\n",
       " '007468.txt',\n",
       " '007407.txt',\n",
       " '004917.txt',\n",
       " '005487.txt',\n",
       " '003947.txt',\n",
       " '006571.txt',\n",
       " '004364.txt',\n",
       " '003598.txt',\n",
       " '006648.txt',\n",
       " '005888.txt',\n",
       " '001112.txt',\n",
       " '005181.txt',\n",
       " '005628.txt',\n",
       " '007232.txt',\n",
       " '001801.txt',\n",
       " '004929.txt',\n",
       " '000362.txt',\n",
       " '002420.txt',\n",
       " '007476.txt',\n",
       " '000702.txt',\n",
       " '007050.txt',\n",
       " '002839.txt',\n",
       " '003762.txt',\n",
       " '004682.txt',\n",
       " '004433.txt',\n",
       " '003107.txt',\n",
       " '004891.txt',\n",
       " '004369.txt',\n",
       " '005723.txt',\n",
       " '000561.txt',\n",
       " '006796.txt',\n",
       " '003063.txt',\n",
       " '004582.txt',\n",
       " '006294.txt',\n",
       " '002202.txt',\n",
       " '004890.txt',\n",
       " '000191.txt',\n",
       " '001158.txt',\n",
       " '001386.txt',\n",
       " '005497.txt',\n",
       " '003136.txt',\n",
       " '006903.txt',\n",
       " '004794.txt',\n",
       " '000311.txt',\n",
       " '001248.txt',\n",
       " '001447.txt',\n",
       " '002292.txt',\n",
       " '002888.txt',\n",
       " '000135.txt',\n",
       " '004822.txt',\n",
       " '004107.txt',\n",
       " '004935.txt',\n",
       " '000704.txt',\n",
       " '005378.txt',\n",
       " '004073.txt',\n",
       " '002948.txt',\n",
       " '003893.txt',\n",
       " '003943.txt',\n",
       " '002755.txt',\n",
       " '001192.txt',\n",
       " '005997.txt',\n",
       " '006320.txt',\n",
       " '005345.txt',\n",
       " '000986.txt',\n",
       " '004843.txt',\n",
       " '000940.txt',\n",
       " '007240.txt',\n",
       " '003737.txt',\n",
       " '005327.txt',\n",
       " '006710.txt',\n",
       " '003331.txt',\n",
       " '001703.txt',\n",
       " '002557.txt',\n",
       " '004593.txt',\n",
       " '001371.txt',\n",
       " '002705.txt',\n",
       " '007427.txt',\n",
       " '003415.txt',\n",
       " '001206.txt',\n",
       " '005768.txt',\n",
       " '003555.txt',\n",
       " '004856.txt',\n",
       " '006653.txt',\n",
       " '003474.txt',\n",
       " '000822.txt',\n",
       " '002851.txt',\n",
       " '005845.txt',\n",
       " '007036.txt',\n",
       " '004554.txt',\n",
       " '003856.txt',\n",
       " '002674.txt',\n",
       " '007374.txt',\n",
       " '004968.txt',\n",
       " '004533.txt',\n",
       " '004040.txt',\n",
       " '002785.txt',\n",
       " '005203.txt',\n",
       " '000454.txt',\n",
       " '007007.txt',\n",
       " '000980.txt',\n",
       " '001314.txt',\n",
       " '005189.txt',\n",
       " '000478.txt',\n",
       " '003067.txt',\n",
       " '006424.txt',\n",
       " '007480.txt',\n",
       " '006860.txt',\n",
       " '003946.txt',\n",
       " '000727.txt',\n",
       " '004874.txt',\n",
       " '003032.txt',\n",
       " '006261.txt',\n",
       " '003036.txt',\n",
       " '007450.txt',\n",
       " '005331.txt',\n",
       " '006990.txt',\n",
       " '003160.txt',\n",
       " '005230.txt',\n",
       " '002263.txt',\n",
       " '004523.txt',\n",
       " '005667.txt',\n",
       " '005297.txt',\n",
       " '007215.txt',\n",
       " '003156.txt',\n",
       " '001002.txt',\n",
       " '003073.txt',\n",
       " '005699.txt',\n",
       " '002625.txt',\n",
       " '001744.txt',\n",
       " '005593.txt',\n",
       " '005762.txt',\n",
       " '000459.txt',\n",
       " '005015.txt',\n",
       " '007046.txt',\n",
       " '005083.txt',\n",
       " '000189.txt',\n",
       " '002875.txt',\n",
       " '006821.txt',\n",
       " '003967.txt',\n",
       " '000334.txt',\n",
       " '005236.txt',\n",
       " '002800.txt',\n",
       " '006207.txt',\n",
       " '002940.txt',\n",
       " '007164.txt',\n",
       " '007451.txt',\n",
       " '001984.txt',\n",
       " '006629.txt',\n",
       " '005624.txt',\n",
       " '003826.txt',\n",
       " '005860.txt',\n",
       " '005196.txt',\n",
       " '003062.txt',\n",
       " '003323.txt',\n",
       " '000138.txt',\n",
       " '006484.txt',\n",
       " '005550.txt',\n",
       " '003601.txt',\n",
       " '003726.txt',\n",
       " '003056.txt',\n",
       " '002168.txt',\n",
       " '000229.txt',\n",
       " '005633.txt',\n",
       " '000399.txt',\n",
       " '004287.txt',\n",
       " '002276.txt',\n",
       " '002314.txt',\n",
       " '004270.txt',\n",
       " '002631.txt',\n",
       " '001880.txt',\n",
       " '002354.txt',\n",
       " '007001.txt',\n",
       " '004578.txt',\n",
       " '006267.txt',\n",
       " '003394.txt',\n",
       " '005185.txt',\n",
       " '001542.txt',\n",
       " '007315.txt',\n",
       " '001693.txt',\n",
       " '005384.txt',\n",
       " '000764.txt',\n",
       " '003671.txt',\n",
       " '000173.txt',\n",
       " '005020.txt',\n",
       " '006421.txt',\n",
       " '007015.txt',\n",
       " '007292.txt',\n",
       " '002635.txt',\n",
       " '005065.txt',\n",
       " '003456.txt',\n",
       " '004656.txt',\n",
       " '006982.txt',\n",
       " '005651.txt',\n",
       " '005066.txt',\n",
       " '006000.txt',\n",
       " '000218.txt',\n",
       " '000739.txt',\n",
       " '000049.txt',\n",
       " '003085.txt',\n",
       " '001941.txt',\n",
       " '004211.txt',\n",
       " '001068.txt',\n",
       " '005453.txt',\n",
       " '007005.txt',\n",
       " '001617.txt',\n",
       " '001161.txt',\n",
       " '003945.txt',\n",
       " '003714.txt',\n",
       " '006497.txt',\n",
       " '003522.txt',\n",
       " '000234.txt',\n",
       " '006819.txt',\n",
       " '001765.txt',\n",
       " '005006.txt',\n",
       " '007442.txt',\n",
       " '003736.txt',\n",
       " '000671.txt',\n",
       " '006812.txt',\n",
       " '007053.txt',\n",
       " '006975.txt',\n",
       " '006974.txt',\n",
       " '001664.txt',\n",
       " '007313.txt',\n",
       " '000292.txt',\n",
       " '006445.txt',\n",
       " '000819.txt',\n",
       " '002256.txt',\n",
       " '000807.txt',\n",
       " '003075.txt',\n",
       " '005202.txt',\n",
       " '002150.txt',\n",
       " '004284.txt',\n",
       " '000745.txt',\n",
       " '002497.txt',\n",
       " '000069.txt',\n",
       " '005870.txt',\n",
       " '005282.txt',\n",
       " '006791.txt',\n",
       " '002721.txt',\n",
       " '001887.txt',\n",
       " '000444.txt',\n",
       " '006892.txt',\n",
       " '004408.txt',\n",
       " '002198.txt',\n",
       " '003316.txt',\n",
       " '003122.txt',\n",
       " '002213.txt',\n",
       " '004126.txt',\n",
       " '001909.txt',\n",
       " '005644.txt',\n",
       " '003492.txt',\n",
       " '005156.txt',\n",
       " '003558.txt',\n",
       " '003854.txt',\n",
       " '002972.txt',\n",
       " '004743.txt',\n",
       " '002179.txt',\n",
       " '003992.txt',\n",
       " '005425.txt',\n",
       " '000144.txt',\n",
       " '000108.txt',\n",
       " '000624.txt',\n",
       " '002349.txt',\n",
       " '003824.txt',\n",
       " '000240.txt',\n",
       " '004971.txt',\n",
       " '007366.txt',\n",
       " '002089.txt',\n",
       " '005640.txt',\n",
       " '004056.txt',\n",
       " '004620.txt',\n",
       " '002723.txt',\n",
       " '004676.txt',\n",
       " '006272.txt',\n",
       " '001581.txt',\n",
       " '002471.txt',\n",
       " '006697.txt',\n",
       " '000143.txt',\n",
       " '003071.txt',\n",
       " '006429.txt',\n",
       " '004069.txt',\n",
       " '003028.txt',\n",
       " '002913.txt',\n",
       " '003219.txt',\n",
       " '000494.txt',\n",
       " '001179.txt',\n",
       " '005780.txt',\n",
       " '003334.txt',\n",
       " '000753.txt',\n",
       " '004528.txt',\n",
       " '000901.txt',\n",
       " '000356.txt',\n",
       " '004280.txt',\n",
       " '004989.txt',\n",
       " '004778.txt',\n",
       " '000845.txt',\n",
       " '006334.txt',\n",
       " '001235.txt',\n",
       " '002441.txt',\n",
       " '006074.txt',\n",
       " '004324.txt',\n",
       " '004239.txt',\n",
       " '000880.txt',\n",
       " '000323.txt',\n",
       " '001395.txt',\n",
       " '005124.txt',\n",
       " '007193.txt',\n",
       " '003780.txt',\n",
       " '002658.txt',\n",
       " '005365.txt',\n",
       " '004956.txt',\n",
       " '002350.txt',\n",
       " '000964.txt',\n",
       " '002936.txt',\n",
       " '000455.txt',\n",
       " '007380.txt',\n",
       " '006488.txt',\n",
       " '004326.txt',\n",
       " '003318.txt',\n",
       " '001021.txt',\n",
       " '006155.txt',\n",
       " '005621.txt',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33d35975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Set to CPU for pillarization or GPU memory might get full\n",
    "device =  torch.device('cpu')\n",
    "\n",
    "class PillarFeatureNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PillarFeatureNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x is of shape (D, P, N)\n",
    "        # Convert it to (P, D, N) for 1x1 convolution      \n",
    "        x = x.to(device)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        ipdb.set_trace()\n",
    "        # Max pooling operation over the points' dimension\n",
    "        x, _ = torch.max(x, dim=2)  # Output shape: (P, C)\n",
    "        return x.T  # Output shape: (C, P)\n",
    "\n",
    "\n",
    "\n",
    "class Pillarization:\n",
    "    def __init__(self, x_min, x_max, y_min, y_max, z_min, z_max, pillar_size, max_points_per_pillar, aug_dim):\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        self.y_min = y_min\n",
    "        self.y_max = y_max\n",
    "        self.z_min = z_min\n",
    "        self.z_max = z_max\n",
    "        self.pillar_size = pillar_size\n",
    "        self.max_points_per_pillar = max_points_per_pillar\n",
    "        self.aug_dim = aug_dim\n",
    "        self.num_x_pillars = int((self.x_max - self.x_min) / self.pillar_size[0])\n",
    "        self.num_y_pillars = int((self.y_max - self.y_min) / self.pillar_size[1])\n",
    "        \n",
    "\n",
    "    def make_pillars(self, points):\n",
    "        \"\"\"\n",
    "        Convert point cloud (x, y, z) into pillars.\n",
    "        \"\"\"\n",
    "        # Mask points outside of our defined boundaries\n",
    "        \n",
    "        mask = (\n",
    "            (points[:, 0] >= self.x_min) & (points[:, 0] <= self.x_max) &\n",
    "            (points[:, 1] >= self.y_min) & (points[:, 1] <= self.y_max) &\n",
    "            (points[:, 2] >= self.z_min) & (points[:, 2] <= self.z_max)\n",
    "        )\n",
    "        points = points[mask]\n",
    "\n",
    "        \n",
    "        # Using numpy's digitize to find the interval/bin each point belongs to.\n",
    "        self.x_indices = torch.tensor(np.digitize(points[:, 0],\n",
    "            np.linspace(self.x_min, self.x_max, self.num_x_pillars))) - 1\n",
    "        \n",
    "        self.y_indices = torch.tensor(np.digitize(points[:, 1], \n",
    "            np.linspace(self.y_min, self.y_max, self.num_y_pillars))) - 1\n",
    "        \n",
    "        pillars = torch.zeros((self.num_x_pillars, self.num_y_pillars, self.max_points_per_pillar, \n",
    "            self.aug_dim))\n",
    "        \n",
    "        # Count how many points are in each pillar to ensure we don't exceed `max_points_per_pillar`\n",
    "        count = torch.zeros((self.num_x_pillars, self.num_y_pillars), dtype=torch.long)\n",
    "        \n",
    "        if (device != torch.device('cpu')):\n",
    "            self.x_indices.to(device)\n",
    "            self.y_indices.to(device)\n",
    "            points = points.to(device)\n",
    "            pillars = pillars.to(device)\n",
    "            count = count.to(device)\n",
    "           \n",
    "        # Calculate pillar x-y center:\n",
    "        pillar_x_center = self.x_indices * self.pillar_size[0] + self.pillar_size[0] / 2.0\n",
    "        pillar_y_center = self.y_indices * self.pillar_size[1] + self.pillar_size[1] / 2.0 \n",
    "\n",
    "        \n",
    "        # TODO: Store points in the pillars in a vectorized way filling the pillars tensor:        \n",
    "        for i in range(points.shape[0]):\n",
    "            x_ind = self.x_indices[i]\n",
    "            y_ind = self.y_indices[i]\n",
    "            \n",
    "            if count[x_ind, y_ind] < self.max_points_per_pillar:\n",
    "                # Compute x_c, y_c and z_c\n",
    "                x_c = (x_ind * self.pillar_size[0] + self.pillar_size[0] / 2.0) - points[i, 0]\n",
    "                y_c = (y_ind * self.pillar_size[1] + self.pillar_size[1] / 2.0) - points[i, 1]\n",
    "                z_c = (self.z_min + self.z_max) / 2 - points[i, 2] # assuming the z-center is the midpoint\n",
    "                \n",
    "                # Calculate pillar center\n",
    "                x_pillar_center = (x_ind * self.pillar_size[0] + self.pillar_size[0] / 2.0)\n",
    "                y_pillar_center = (y_ind * self.pillar_size[1] + self.pillar_size[1] / 2.0)\n",
    "                \n",
    "                # Add original x, y, and z coordinates, then x_c, y_c, z_c\n",
    "                pillars[x_ind, y_ind, count[x_ind, y_ind], :3] = points[i, :3]\n",
    "                \n",
    "                if (device != torch.device('cpu')): \n",
    "                    pillars[x_ind, y_ind, count[x_ind, y_ind], 3:6] = torch.tensor([x_c, y_c, z_c]).to(device)\n",
    "                else: \n",
    "                    pillars[x_ind, y_ind, count[x_ind, y_ind], 3:6] = torch.tensor([x_c, y_c, z_c])\n",
    "                    \n",
    "                pillars[x_ind, y_ind, count[x_ind, y_ind], 6] = x_pillar_center - pillars[x_ind, y_ind, count[x_ind, y_ind], 0]\n",
    "                pillars[x_ind, y_ind, count[x_ind, y_ind], 7] = y_pillar_center - pillars[x_ind, y_ind, count[x_ind, y_ind], 1]\n",
    "                \n",
    "                count[x_ind, y_ind] += 1\n",
    "                \n",
    "        \n",
    "        # Zero-padding if too few point, random sampling if too many points:\n",
    "        for i in range(self.num_x_pillars):\n",
    "            for j in range(self.num_y_pillars):\n",
    "                if pillars[i, j].shape[0] > self.max_points_per_pillar:\n",
    "                    # Randomly sample points if there are too many for a given pillar\n",
    "                    pillars[i, j] = pillars[i, j][torch.randperm(pillars[i, j].shape[0])[:self.max_points_per_pillar]]\n",
    "                elif pillars[i, j].shape[0] < self.max_points_per_pillar:\n",
    "                    # Zero pad if there are too few points for a given pillar\n",
    "                    pillars[i, j] = torch.cat((pillars[i, j], torch.zeros((self.max_points_per_pillar - \n",
    "                                                                           pillars[i, j].shape[0], pillars[i, j].shape[1]))))\n",
    "        \n",
    "        # Reshape pillars to size (D,P,N):\n",
    "        pillars = pillars.permute(3, 0, 1, 2).reshape(D, -1, N)\n",
    "        \n",
    "        return pillars\n",
    "\n",
    "\n",
    "class PseudoImageDataset(Dataset):\n",
    "    def __init__(self, train_dir, D, N, transform=None):\n",
    "        self.train_dir = train_dir\n",
    "        self.filenames = [f for f in os.listdir(train_dir) if os.path.isfile(os.path.join(train_dir, f))]\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.pillarizer = Pillarization(aug_dim=D, x_min=-40.0, x_max=40.0, y_min=-25.0, y_max=25.0, \n",
    "                                        z_min=-3, z_max=3, pillar_size=(0.5, 0.5), max_points_per_pillar=N)\n",
    "        self.feature_extractor = PillarFeatureNet(D, 64)  # TODO: Don't hardcode me\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        point_cloud = train_set.load_point_cloud_from_bin(os.path.join(self.train_dir, self.filenames[idx]))\n",
    "        pillars = self.pillarizer.make_pillars(point_cloud)\n",
    "        \n",
    "        # Apply linear activation, batchnorm, and ReLU for feature extraction from pillars tensor\n",
    "        features = self.feature_extractor(pillars)\n",
    "        \n",
    "        # Generate pseudo-image (GPU)\n",
    "        pseudo_image = torch.zeros(features.shape[0], self.pillarizer.num_y_pillars, self.pillarizer.num_x_pillars).to(device)\n",
    "        \n",
    "        # Scatter the features back to their original pillar locations\n",
    "        print(f'Loading point cloud number {idx}')\n",
    "        for i in range(features.shape[1]):\n",
    "            x_ind = self.pillarizer.x_indices[i].long() # SUS: Is the indexing here correct?\n",
    "            y_ind = self.pillarizer.y_indices[i].long()\n",
    "            pseudo_image[:, y_ind, x_ind] = features[:, i]\n",
    "\n",
    "        \n",
    "        if self.transform:\n",
    "            pseudo_image = self.transform(pseudo_image)\n",
    "            \n",
    "        return pseudo_image\n",
    "        \n",
    "        \n",
    "# Create the dataset and DataLoader\n",
    "D = 9\n",
    "N = 100\n",
    "dataset = PseudoImageDataset(train_dir=train_dir, D=D, N=N)\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, get batches of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2050086/3895991962.py:23: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.from_numpy(point_cloud)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading point cloud number 5995\n",
      "Loading point cloud number 4978\n",
      "Loading point cloud number 1309\n",
      "Loading point cloud number 3359\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (pseudo_image) in enumerate(train_loader):\n",
    "    break\n",
    "\n",
    "# After pillarization and batching, we can start using the GPU:\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backbone pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, L, stride):\n",
    "        super(Block, self).__init__()\n",
    "        layers = []\n",
    "        # First layer with the specified stride\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1))\n",
    "        layers.append(nn.BatchNorm2d(out_channels)) # TODO -> Uncomment and batch\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Subsequent layers with stride 1\n",
    "        for _ in range(1, L):\n",
    "            layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, output_padding):\n",
    "        super(UpSample, self).__init__()\n",
    "        # Assuming stride_out is always half of stride_in based on the diagram\n",
    "        self.up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, output_padding=output_padding),\n",
    "            nn.BatchNorm2d(out_channels), # TODO> Uncomment and batch\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.up(x)\n",
    "\n",
    "class BackBone(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(BackBone, self).__init__()\n",
    "\n",
    "        # Define blocks with arbitrary L for now (can be tuned based on requirements)\n",
    "        self.block1 = Block(in_channels, out_channels*2, L=3, stride=1)\n",
    "        self.block2 = Block(out_channels*2, out_channels*2, L=3, stride=2)\n",
    "        self.block3 = Block(out_channels*2, out_channels*2, L=3, stride=2)\n",
    "        \n",
    "\n",
    "        # Define upsampling layers        \n",
    "        self.up1 = UpSample(out_channels*2, out_channels*2, stride=1, output_padding=0)\n",
    "        self.up2 = UpSample(out_channels*2, out_channels*2, stride=2, output_padding=1)\n",
    "        self.up3 = UpSample(out_channels*2, out_channels*2, stride=4, output_padding=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.block1(x)\n",
    "        x2 = self.block2(x1)\n",
    "        x3 = self.block3(x2)\n",
    "        x2.size()\n",
    "        # Upsample and concatenate\n",
    "        up_x1 = self.up1(x1)   \n",
    "        up_x2 = self.up2(x2)\n",
    "        up_x3 = self.up3(x3)     \n",
    "        concat_features = torch.cat([up_x1, up_x2, up_x3], dim=1)\n",
    "        \n",
    "        return concat_features\n",
    "\n",
    "    \n",
    "backbone = BackBone(in_channels=64, out_channels=64)\n",
    "backbone_features = backbone(pseudo_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 384, 100, 160])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_features.size()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement the Detection Head:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionHead(nn.Module):\n",
    "    def __init__(self, in_channels, grid_size_x, grid_size_y, num_anchors, num_classes):\n",
    "        super(DetectionHead, self).__init__()\n",
    "        self.grid_size_x = grid_size_x\n",
    "        self.grid_size_y = grid_size_y\n",
    "        self.num_anchors = num_anchors\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Assuming 4 anchor boxes per cell\n",
    "        self.loc_layer = nn.Conv2d(in_channels, num_anchors * 3, 1)\n",
    "        self.size_layer = nn.Conv2d(in_channels, num_anchors * 3, 1)\n",
    "        self.clf_layer = nn.Conv2d(in_channels, num_anchors * (num_classes + 1), 1) # +1 for confidence score\n",
    "        self.occupancy_layer = nn.Conv2d(in_channels, num_anchors * 1, 1)\n",
    "        self.angle_layer = nn.Conv2d(in_channels, num_anchors * 1, 1)\n",
    "        self.heading_layer = nn.Conv2d(in_channels, num_anchors * 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        loc = self.loc_layer(x).view(x.size(0), self.num_anchors, 3, self.grid_size_x, self.grid_size_y)\n",
    "        size = self.size_layer(x).view(x.size(0), self.num_anchors, 3, self.grid_size_x, self.grid_size_y)\n",
    "        clf = self.clf_layer(x).view(x.size(0), self.num_anchors, self.num_classes + 1, self.grid_size_x, self.grid_size_y)\n",
    "        occupancy = self.occupancy_layer(x).view(x.size(0), self.num_anchors, 1, self.grid_size_x, self.grid_size_y)\n",
    "        angle = self.angle_layer(x).view(x.size(0), self.num_anchors, 1, self.grid_size_x, self.grid_size_y)\n",
    "        heading = self.heading_layer(x).view(x.size(0), self.num_anchors, 1, self.grid_size_x, self.grid_size_y)\n",
    "\n",
    "        # Adjust the shape to match the output as per the provided image. \n",
    "        #loc = loc.permute(0, 3, 4, 1, 2)\n",
    "        #size = size.permute(0, 3, 4, 1, 2)\n",
    "        #clf = clf.permute(0, 3, 4, 1, 2)\n",
    "        #occupancy = occupancy.permute(0, 3, 4, 1, 2)\n",
    "        #angle = angle.permute(0, 3, 4, 1, 2)\n",
    "        #heading = heading.permute(0, 3, 4, 1, 2)\n",
    "\n",
    "        return loc, size, clf, occupancy, angle, heading\n",
    "\n",
    "\n",
    "#backbone_output = torch.randn(4, backbone_features.size()[1], 252, 252) # Example feature map from backbone\n",
    "detection_head = DetectionHead(backbone_features.size()[1], backbone_features.size()[2], \n",
    "                        backbone_features.size()[3], num_anchors=1, num_classes=2) # Initialize with correct parameters\n",
    "loc, size, clf, occupancy, angle, heading = detection_head(backbone_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 3, 100, 160])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0429, -0.0443, -0.0088,  ...,  0.0088, -0.0071, -0.0120],\n",
       "          [ 0.0092, -0.1676,  0.0165,  ..., -0.0987, -0.0149, -0.0155],\n",
       "          [-0.0227, -0.0605, -0.0418,  ..., -0.0590, -0.0411, -0.0273],\n",
       "          ...,\n",
       "          [-0.0327, -0.1672, -0.0510,  ..., -0.0833, -0.0099, -0.0402],\n",
       "          [-0.0260, -0.0372, -0.0325,  ..., -0.0378, -0.0255, -0.0422],\n",
       "          [-0.0490, -0.0897, -0.0574,  ..., -0.0790, -0.0282, -0.0280]],\n",
       "\n",
       "         [[-0.1106,  0.0586, -0.0007,  ...,  0.0246,  0.0050,  0.0606],\n",
       "          [-0.0108, -0.0386,  0.0002,  ..., -0.0153,  0.0149,  0.0180],\n",
       "          [-0.0167,  0.0717, -0.0153,  ...,  0.0562, -0.0230,  0.0447],\n",
       "          ...,\n",
       "          [ 0.0021, -0.0744,  0.0250,  ..., -0.0310,  0.0309, -0.0089],\n",
       "          [ 0.0029,  0.0765,  0.0075,  ...,  0.0653, -0.0212,  0.0456],\n",
       "          [ 0.0725, -0.0052,  0.0326,  ...,  0.0029,  0.0207,  0.0124]],\n",
       "\n",
       "         [[ 0.0831,  0.0483,  0.0100,  ...,  0.0428,  0.0171, -0.0227],\n",
       "          [ 0.0520,  0.0444, -0.0151,  ...,  0.0690, -0.0051,  0.0036],\n",
       "          [ 0.0124,  0.0496,  0.0286,  ...,  0.0305,  0.0202, -0.0180],\n",
       "          ...,\n",
       "          [ 0.0181,  0.0675, -0.0325,  ...,  0.0997, -0.0182,  0.0209],\n",
       "          [-0.0255,  0.0617, -0.0070,  ...,  0.0533,  0.0167,  0.0078],\n",
       "          [-0.0296,  0.0213, -0.0025,  ...,  0.0050, -0.0058,  0.0195]]]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc[0,:,:,:,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
