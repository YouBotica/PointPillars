{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d41b4f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bd5b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KITTIDataset(Dataset):\n",
    "    def __init__(self, root_dir, debug=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the point clouds.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.files = [f for f in os.listdir(root_dir) if os.path.isfile(os.path.join(root_dir, f))]\n",
    "            \n",
    "        if debug:\n",
    "            random_sample = random.randint(1, 7400)\n",
    "            self.files = [self.files[random_sample]]\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        point_cloud_path = os.path.join(self.root_dir, self.files[idx])\n",
    "        point_cloud = self.load_point_cloud_from_bin(point_cloud_path)  # Assuming point clouds are stored as .pt files\n",
    "        return point_cloud\n",
    "    \n",
    "    def load_point_cloud_from_bin(self, root_dir):\n",
    "        with open(bin_path, 'rb') as f:\n",
    "            content = f.read()\n",
    "            point_cloud = np.frombuffer(content, dtype=np.float32)\n",
    "            point_cloud = point_cloud.reshape(-1, 4)  # KITTI point clouds are (x, y, z, intensity)\n",
    "        return torch.from_numpy(point_cloud)\n",
    "        \n",
    "\n",
    "train_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/velodyne_reduced'\n",
    "test_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/testing/velodyne_reduced'\n",
    "# TODO: Add label dir\n",
    "\n",
    "train_set = KITTIDataset(root_dir=train_dir, debug=False)\n",
    "test_set = KITTIDataset(root_dir=test_dir, debug=False)\n",
    "\n",
    "batched_train_set = DataLoader(train_set, batch_size=4, shuffle=False)\n",
    "batched_test_set = DataLoader(train_set, batch_size=4, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d430264d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/velodyne_reduced/000039.bin'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "678a7061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90080/2119310883.py:134: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  pillars = pillarizer.make_pillars(torch.from_numpy(point_cloud))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class PillarFeatureNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PillarFeatureNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x is of shape (D, P, N)\n",
    "        # Convert it to (P, D, N) for 1x1 convolution\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # Max pooling operation over the points' dimension\n",
    "        x, _ = torch.max(x, dim=2)  # Output shape: (P, C)\n",
    "        return x.T  # Output shape: (C, P)\n",
    "\n",
    "\n",
    "\n",
    "class Pillarization:\n",
    "    def __init__(self, x_min, x_max, y_min, y_max, z_min, z_max, pillar_size, max_points_per_pillar, aug_dim):\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        self.y_min = y_min\n",
    "        self.y_max = y_max\n",
    "        self.z_min = z_min\n",
    "        self.z_max = z_max\n",
    "        self.pillar_size = pillar_size\n",
    "        self.max_points_per_pillar = max_points_per_pillar\n",
    "        self.aug_dim = aug_dim\n",
    "        self.num_x_pillars = int((self.x_max - self.x_min) / self.pillar_size[0])\n",
    "        self.num_y_pillars = int((self.y_max - self.y_min) / self.pillar_size[1])\n",
    "        \n",
    "\n",
    "    def make_pillars(self, points):\n",
    "        \"\"\"\n",
    "        Convert point cloud (x, y, z) into pillars.\n",
    "        \"\"\"\n",
    "        # Mask points outside of our defined boundaries\n",
    "        \n",
    "        mask = (\n",
    "            (points[:, 0] >= self.x_min) & (points[:, 0] <= self.x_max) &\n",
    "            (points[:, 1] >= self.y_min) & (points[:, 1] <= self.y_max) &\n",
    "            (points[:, 2] >= self.z_min) & (points[:, 2] <= self.z_max)\n",
    "        )\n",
    "        points = points[mask]\n",
    "\n",
    "        \n",
    "        # Using numpy's digitize to find the interval/bin each point belongs to.\n",
    "        # TODO: Get rid of these unnecessary copies of tensors\n",
    "        self.x_indices = torch.tensor(np.digitize(points[:, 0], np.linspace(self.x_min, self.x_max, self.num_x_pillars))) - 1\n",
    "        self.y_indices = torch.tensor(np.digitize(points[:, 1], np.linspace(self.y_min, self.y_max, self.num_y_pillars))) - 1\n",
    "\n",
    "        # TODO: Calculate pillar x-y center:\n",
    "        pillar_x_center = self.x_indices * self.pillar_size[0] + self.pillar_size[0] / 2.0\n",
    "        pillar_y_center = self.y_indices * self.pillar_size[1] + self.pillar_size[1] / 2.0 \n",
    "\n",
    "        pillars = torch.zeros((self.num_x_pillars, self.num_y_pillars, self.max_points_per_pillar, self.aug_dim))\n",
    "        \n",
    "        # Count how many points are in each pillar to ensure we don't exceed `max_points_per_pillar`\n",
    "        count = torch.zeros((self.num_x_pillars, self.num_y_pillars), dtype=torch.long)\n",
    "        \n",
    "        # TODO: Store points in the pillars in a vectorized way filling the pillars tensor:        \n",
    "        for i in range(points.shape[0]):\n",
    "            x_ind = self.x_indices[i]\n",
    "            y_ind = self.y_indices[i]\n",
    "            \n",
    "            if count[x_ind, y_ind] < self.max_points_per_pillar:\n",
    "                # Compute x_c, y_c and z_c\n",
    "                x_c = (x_ind * self.pillar_size[0] + self.pillar_size[0] / 2.0) - points[i, 0]\n",
    "                y_c = (y_ind * self.pillar_size[1] + self.pillar_size[1] / 2.0) - points[i, 1]\n",
    "                z_c = (self.z_min + self.z_max) / 2 - points[i, 2] # assuming the z-center is the midpoint\n",
    "                \n",
    "                # Calculate pillar center\n",
    "                x_pillar_center = (x_ind * self.pillar_size[0] + self.pillar_size[0] / 2.0)\n",
    "                y_pillar_center = (y_ind * self.pillar_size[1] + self.pillar_size[1] / 2.0)\n",
    "                \n",
    "                # Add original x, y, and z coordinates, then x_c, y_c, z_c\n",
    "                pillars[x_ind, y_ind, count[x_ind, y_ind], :3] = points[i, :3]\n",
    "                pillars[x_ind, y_ind, count[x_ind, y_ind], 3:6] = torch.tensor([x_c, y_c, z_c]) # Sus\n",
    "                pillars[x_ind, y_ind, count[x_ind, y_ind], 6] = x_pillar_center - pillars[x_ind, y_ind, count[x_ind, y_ind], 0]\n",
    "                pillars[x_ind, y_ind, count[x_ind, y_ind], 7] = y_pillar_center - pillars[x_ind, y_ind, count[x_ind, y_ind], 1]\n",
    "                \n",
    "                count[x_ind, y_ind] += 1\n",
    "        \n",
    "        # Zero-padding if too few point, random sampling if too many points:\n",
    "        for i in range(self.num_x_pillars):\n",
    "            for j in range(self.num_y_pillars):\n",
    "                if pillars[i, j].shape[0] > self.max_points_per_pillar:\n",
    "                    # Randomly sample points if there are too many for a given pillar\n",
    "                    pillars[i, j] = pillars[i, j][torch.randperm(pillars[i, j].shape[0])[:self.max_points_per_pillar]]\n",
    "                elif pillars[i, j].shape[0] < self.max_points_per_pillar:\n",
    "                    # Zero pad if there are too few points for a given pillar\n",
    "                    pillars[i, j] = torch.cat((pillars[i, j], torch.zeros((self.max_points_per_pillar - pillars[i, j].shape[0], pillars[i, j].shape[1]))))\n",
    "        \n",
    "        # Reshape pillars to size (D,P,N):\n",
    "        pillars = pillars.permute(3, 0, 1, 2).reshape(D, -1, N)\n",
    "        \n",
    "        return pillars\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "            \n",
    "# Pillarization testing:\n",
    "\n",
    "# TODO: Get a random sample:\n",
    "def load_point_cloud_from_bin(bin_path):\n",
    "    with open(bin_path, 'rb') as f:\n",
    "        content = f.read()\n",
    "        point_cloud = np.frombuffer(content, dtype=np.float32)\n",
    "        point_cloud = point_cloud.reshape(-1, 4)  # KITTI point clouds are (x, y, z, intensity)\n",
    "    \n",
    "    x = point_cloud[:, 0]\n",
    "    y = point_cloud[:, 1]\n",
    "    z = point_cloud[:, 2]\n",
    "    \n",
    "    return point_cloud\n",
    "\n",
    "# Example usage\n",
    "random_sample = random.randint(1, 7400)\n",
    "bin_path = os.path.join(train_dir, '000039.bin')\n",
    "point_cloud = load_point_cloud_from_bin(bin_path)\n",
    "\n",
    "# TODO: Pillarize the sample:\n",
    "D = 9 # Augmented dimension\n",
    "N = 100 # Max number of points per pillar\n",
    "\n",
    "pillarizer = Pillarization(aug_dim=D, x_min=-40.0, x_max=40.0, y_min=-25.0, y_max=25.0, \n",
    "           z_min=-3, z_max=3, pillar_size=(0.5, 0.5), max_points_per_pillar=N)\n",
    "\n",
    "pillars = pillarizer.make_pillars(torch.from_numpy(point_cloud)) \n",
    "\n",
    "\n",
    "# Apply linear activation, batchnorm and ReLU for feature extraction from pillars tensor:\n",
    "feature_extractor = PillarFeatureNet(D, 64)\n",
    "features = feature_extractor(pillars)     \n",
    "\n",
    "# Generate pseudo-image\n",
    "pseudo_image = torch.zeros(features.shape[0], pillarizer.num_y_pillars, pillarizer.num_x_pillars) # Empty canvas\n",
    "\n",
    "\n",
    "# Scatter the features back to their original pillar locations\n",
    "for i in range(features.shape[1]):\n",
    "    x_ind = pillarizer.x_indices[i].long()\n",
    "    y_ind = pillarizer.y_indices[i].long()\n",
    "    pseudo_image[:, y_ind, x_ind] = features[:, i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5d752a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100, 160])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7381ba2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, L, stride):\n",
    "        super(Block, self).__init__()\n",
    "        layers = []\n",
    "        # First layer with the specified stride\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1))\n",
    "        #layers.append(nn.BatchNorm2d(out_channels)) # TODO -> Uncomment and batch\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Subsequent layers with stride 1\n",
    "        for _ in range(1, L):\n",
    "            layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1))\n",
    "            #layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, output_padding):\n",
    "        super(UpSample, self).__init__()\n",
    "        # Assuming stride_out is always half of stride_in based on the diagram\n",
    "        self.up = nn.Sequential(\n",
    "            # nn.Upsample(scale_factor=gain),\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, output_padding=output_padding),\n",
    "            # nn.BatchNorm2d(out_channels), # TODO> Uncomment and batch\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.up(x)\n",
    "\n",
    "class BackBone(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(BackBone, self).__init__()\n",
    "\n",
    "        # Define blocks with arbitrary L for now (can be tuned based on requirements)\n",
    "        self.block1 = Block(in_channels, out_channels*2, L=3, stride=1)\n",
    "        self.block2 = Block(out_channels*2, out_channels*2, L=3, stride=2)\n",
    "        self.block3 = Block(out_channels*2, out_channels*2, L=3, stride=2)\n",
    "        \n",
    "\n",
    "        # Define upsampling layers        \n",
    "        self.up1 = UpSample(out_channels*2, out_channels*2, stride=1, output_padding=0)\n",
    "        self.up2 = UpSample(out_channels*2, out_channels*2, stride=2, output_padding=1)\n",
    "        self.up3 = UpSample(out_channels*2, out_channels*2, stride=4, output_padding=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.block1(x)\n",
    "        x2 = self.block2(x1)\n",
    "        x3 = self.block3(x2)\n",
    "        x2.size()\n",
    "        # Upsample and concatenate\n",
    "        up_x1 = self.up1(x1)   \n",
    "        up_x2 = self.up2(x2)\n",
    "        up_x3 = self.up3(x3)     \n",
    "        concat_features = torch.cat([up_x1, up_x2, up_x3], dim=0)\n",
    "        \n",
    "        return concat_features\n",
    "\n",
    "    \n",
    "backbone = BackBone(in_channels=64, out_channels=64)\n",
    "backbone_features = backbone(pseudo_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a962d605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 100, 160])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97be448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86a06a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100, 160])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ad984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd989dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f869c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f647244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
