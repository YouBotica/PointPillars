{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Can I can use GPU now? -- True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdb\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import ipdb\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pipelines (a.k.a parts of the Neural Network)\n",
    "from Pipelines.kitti_loader import KITTIDataset\n",
    "from Pipelines.pillarizer import PillarFeatureNet, Pillarization, PseudoImageDataset\n",
    "from Pipelines.anchors import Box2D, Anchor\n",
    "\n",
    "\n",
    "from Utils.transformations import transform_to_canvas, transform_to_grid, map_to_img\n",
    "from Utils.collate import normalize_annotations \n",
    "from Utils.boxes import create_boxes_tensor \n",
    "\n",
    "# Visualization tools:\n",
    "from Visualization.visz_pointcloud_w_label import plot_point_cloud_with_bboxes_o3d\n",
    "from Visualization.visz_bboxes import visualize_batch_bounding_boxes\n",
    "\n",
    "# Some Neural Network Parameters:\n",
    "AUG_DIM = 9\n",
    "MAX_POINTS_PER_PILLAR = 100\n",
    "MAX_FILLED_PILLARS = 12000\n",
    "X_MIN = 0.0\n",
    "X_MAX = 70.4\n",
    "Y_MIN = -40.0\n",
    "Y_MAX = 40.0\n",
    "Z_MIN = -3.0\n",
    "Z_MAX = 1.0\n",
    "PILLAR_SIZE = (0.16, 0.16)\n",
    "DESIRED_CLASSES = ['Car'] # More classes can be added here\n",
    "SCALE_FACTOR = 1.5\n",
    "H = 500\n",
    "W = 440\n",
    "\n",
    "\n",
    "ANCHORS = torch.tensor([[3.9, 1.6, 1.56, -1, 0], # Anchors as tensor: (height, width, height, z_center, orientation)\n",
    "                       [1.6, 3.9, 1.56, -1, 1.5708],\n",
    "                       [0.8, 0.6, 1.73, -0.6, 0],\n",
    "                       [0.6, 0.8, 1.73, -0.6, 1.5708]]\n",
    "                       )\n",
    "\n",
    "mapped_anchors = ANCHORS.detach().clone()\n",
    "mapped_anchors[:,0:2] /= PILLAR_SIZE[0]\n",
    "\n",
    "\n",
    "# Define a dictionary to map attributes to their indices\n",
    "attributes_idx = {\n",
    "    'norm_x': 7,\n",
    "    'norm_y': 8,\n",
    "    'norm_z': 9,\n",
    "    'norm_h': 10,\n",
    "    'norm_w': 11,\n",
    "    'norm_l': 12,\n",
    "}\n",
    "\n",
    "# Create an anchor: \n",
    "anchor = Anchor(width=mapped_anchors[0][1], height=mapped_anchors[0][1]) # TODO: Add more anchors for better learning\n",
    "anchor.create_anchor_grid(H,W) # Creates grid\n",
    "anchor.create_anchors()\n",
    "\n",
    "\n",
    "print(f'Can I can use GPU now? -- {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1001 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/Pipelines/kitti_loader.py:50: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.from_numpy(point_cloud)\n",
      " 25%|██▌       | 251/1001 [16:14<47:59,  3.84s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceeded count of size torch.Size([440, 500]) with indices x: 440 y: 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 280/1001 [18:07<46:36,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceeded count of size torch.Size([440, 500]) with indices x: 331 y: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 594/1001 [38:22<24:57,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceeded count of size torch.Size([440, 500]) with indices x: 440 y: 358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 726/1001 [46:45<18:00,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceeded count of size torch.Size([440, 500]) with indices x: 429 y: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 771/1001 [49:41<15:07,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_2609299/2510407808.py\u001b[0m(31)\u001b[0;36mnormalize_annotations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     30 \u001b[0;31m            \u001b[0;31m# Fill in the tensor with both original and normalized values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 31 \u001b[0;31m            annotations_tensor[j] = torch.tensor([\n",
      "\u001b[0m\u001b[0;32m     32 \u001b[0;31m                \u001b[0morig_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_ry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 771/1001 [50:42<15:07,  3.95s/it]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 15 is out of bounds for dimension 0 with size 15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(train_set))):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39m# Get the point cloud and corresponding label\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     point_cloud, label \u001b[39m=\u001b[39m train_set[idx]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     label_as_tensor \u001b[39m=\u001b[39m normalize_annotations(annotations\u001b[39m=\u001b[39;49mlabel, pillar_size\u001b[39m=\u001b[39;49mPILLAR_SIZE,  \u001b[39m# FIXME: ADD A RETURN STATEMENT\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m             x_lims\u001b[39m=\u001b[39;49m(X_MIN, X_MAX), y_lims\u001b[39m=\u001b[39;49m(Y_MIN, Y_MAX))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39m# Pillarize the point cloud\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     pillars, x_indices, y_indices \u001b[39m=\u001b[39m pillarizer\u001b[39m.\u001b[39mmake_pillars(point_cloud)\n",
      "\u001b[1;32m/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m             ipdb\u001b[39m.\u001b[39mset_trace()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         \u001b[39m# Fill in the tensor with both original and normalized values\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         annotations_tensor[j] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m             orig_x, orig_y, orig_z, orig_h, orig_w, orig_l, orig_ry,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m             norm_x, norm_y, norm_z, norm_h, norm_w, norm_l, orig_ry  \u001b[39m# Note: rotation_y remains the same\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m'''annotations tensor of size (max_gt_boxes, num_attributes) -> (15, 14)'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adlink/Documents/ECE-57000/ClassProject/github/PointPillars/Implementation/pointcloud2pillars.ipynb#W1sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mreturn\u001b[39;00m annotations_tensor\n",
      "\u001b[0;31mIndexError\u001b[0m: index 15 is out of bounds for dimension 0 with size 15"
     ]
    }
   ],
   "source": [
    "# Converter from pointcloud to pillars representation:\n",
    "\n",
    "small_train_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_train_velodyne'\n",
    "small_train_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/small_labels_velodyne'\n",
    "\n",
    "mini_train_pointclouds_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_train_velodyne'\n",
    "mini_train_labels_dir = '/home/adlink/Documents/ECE-57000/ClassProject/Candidate2/PointPillars/dataset/kitti/training/mini_label_velodyne'\n",
    "\n",
    "device =  torch.device('cpu') # CPU should be used for pillarization\n",
    "\n",
    "train_set = KITTIDataset(pointcloud_dir=small_train_pointclouds_dir, labels_dir=small_train_labels_dir)\n",
    "pillarizer = Pillarization(device=device, aug_dim=AUG_DIM, x_min=X_MIN, x_max=X_MAX, y_min=Y_MIN, y_max=Y_MAX, \n",
    "                                z_min=Z_MIN, z_max=Z_MAX, pillar_size=PILLAR_SIZE, \n",
    "                                max_points_per_pillar=MAX_POINTS_PER_PILLAR, max_pillars=MAX_FILLED_PILLARS)\n",
    "\n",
    "\n",
    "\n",
    "# We'll save the data in an HDF5 file\n",
    "with h5py.File('/media/adlink/6a738988-44b7-4696-ba07-3daeb00e5683/kitti_pillars/pillar_data.h5', 'w') as h5f:\n",
    "    # Iterate through all point clouds in the dataset\n",
    "    for idx in tqdm(range(len(train_set))):\n",
    "        # Get the point cloud and corresponding label\n",
    "        point_cloud, label = train_set[idx]\n",
    "\n",
    "        label_as_tensor = normalize_annotations(annotations=label, pillar_size=PILLAR_SIZE,  # FIXME: ADD A RETURN STATEMENT\n",
    "                x_lims=(X_MIN, X_MAX), y_lims=(Y_MIN, Y_MAX))\n",
    "        \n",
    "        # Pillarize the point cloud\n",
    "        pillars, x_indices, y_indices = pillarizer.make_pillars(point_cloud)\n",
    "        \n",
    "        # Unbatch to store locally:\n",
    "        pillars = pillars.squeeze(0) \n",
    "        x_indices = x_indices.squeeze(0)\n",
    "        y_indices = y_indices.squeeze(0)\n",
    "        \n",
    "        # Convert to numpy and write to HDF5\n",
    "        grp = h5f.create_group(f'point_cloud_{idx}')\n",
    "        grp.create_dataset('pillars', data=pillars.numpy())\n",
    "        grp.create_dataset('x_indices', data=x_indices.numpy())\n",
    "        grp.create_dataset('y_indices', data=y_indices.numpy())\n",
    "        grp.create_dataset('label', data=label_as_tensor.numpy()) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
